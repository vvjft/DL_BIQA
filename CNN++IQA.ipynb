{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPA06EDSKNsZUfOcyCiO70N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vvjft/DL_BIQA/blob/main/CNN%2B%2BIQA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "W2gnpJseVXpx"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import scipy\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') # LIVE\n",
        "!cp -r /content/drive/MyDrive/magisterka/LIVEIQA_release2 /content\n",
        "os.rename('/content/LIVEIQA_release2', '/content/LIVE')\n",
        "drive.flush_and_unmount()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cgsBG13VYbq",
        "outputId": "317c5818-77a0-485a-bf65-2aa368b56b44"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.signal import convolve2d\n",
        "def normalize_and_slice(db_dir, train_data, val_data, test_data, patch_size=32, cross=False):\n",
        "\n",
        "  def local_normalize(patch, P=3, Q=3, C=1):\n",
        "      kernel = np.ones((P, Q)) / (P * Q)\n",
        "      patch_mean = convolve2d(patch, kernel, boundary='symm', mode='same')\n",
        "      patch_sm = convolve2d(np.square(patch), kernel, boundary='symm', mode='same')\n",
        "      patch_std = np.sqrt(np.maximum(patch_sm - np.square(patch_mean), 0)) + C\n",
        "      patch_ln = (patch - patch_mean) / patch_std\n",
        "      return patch_ln.astype('float32')\n",
        "\n",
        "  sets = {'train': [train_data, 'training'], 'val':[val_data, 'validation'], 'test':[test_data, 'test']}\n",
        "\n",
        "  for key, (data, name) in sets.items():\n",
        "\n",
        "    output_dir_full = f'{db_dir}/normalized_distorted_images/{name}/full/' # where to store normalized distorted images\n",
        "    output_dir_patches = f'{db_dir}/normalized_distorted_images/{name}/patches/' # where to store patches\n",
        "    norm_file_info_path = f'{db_dir}/normalized_distorted_images/{name}/norm_{name}.csv'\n",
        "    patch_file_info_path = f'{db_dir}/normalized_distorted_images/{name}/patch_{name}.csv'\n",
        "    os.makedirs(output_dir_full, exist_ok=True)\n",
        "    os.makedirs(output_dir_patches, exist_ok=True)\n",
        "\n",
        "    norm_info_list = []\n",
        "    patch_info_list = []\n",
        "\n",
        "    for index, row in data.iterrows():\n",
        "        image_filename = row[0]\n",
        "        mos_value = row[1]\n",
        "        distortion = row[2]\n",
        "        image_path = f'{db_dir}/distorted_images/{image_filename}'\n",
        "        image = cv2.imread(image_path)\n",
        "\n",
        "        if image is None:\n",
        "            print(f\"Failed to load image: {image_filename}\")\n",
        "            continue\n",
        "\n",
        "        # Normalize the image\n",
        "        image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        image_normalized = local_normalize(image_gray)\n",
        "        # Save\n",
        "        image_filename = f'NORM_{image_filename}'\n",
        "        norm_info_list.append([image_filename, mos_value, distortion])\n",
        "        cv2.imwrite(output_dir_full+image_filename, image_normalized)\n",
        "        # Slice to patches\n",
        "        height, width = image_normalized.shape[:2]\n",
        "        num_patches_y = height // patch_size\n",
        "        num_patches_x = width // patch_size\n",
        "        patch_count = 0\n",
        "        for i in range(num_patches_y):\n",
        "            for j in range(num_patches_x):\n",
        "                patch = image_normalized[i*patch_size:(i+1)*patch_size, j*patch_size:(j+1)*patch_size]\n",
        "                patch_path = os.path.join(output_dir_patches, f\"{os.path.splitext(image_filename)[0]}_patch_{patch_count}.bmp\")\n",
        "                patch_filename = f\"{os.path.splitext(image_filename)[0]}_patch_{patch_count}.bmp\"\n",
        "                cv2.imwrite(patch_path, patch)\n",
        "                # Add patch info to the list\n",
        "                patch_info_list.append([patch_filename, mos_value, distortion])\n",
        "                patch_count += 1\n",
        "\n",
        "    norm_info_df = pd.DataFrame(norm_info_list, columns=['image_filename', score_measure, 'Distortion'])\n",
        "    norm_info_df.to_csv(norm_file_info_path, index=False)\n",
        "    print(f\"[{name}]: Saved full normalized distorted image info to:\\n{patch_file_info_path}.\")\n",
        "    patch_info_df = pd.DataFrame(patch_info_list, columns=['image_filename', score_measure, 'Distortion'])\n",
        "    patch_info_df.to_csv(patch_file_info_path, index=False)\n",
        "    print(f\"[{name}]: Saved patch info to {patch_file_info_path}.\")"
      ],
      "metadata": {
        "id": "QUB6T8EIVf9p"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
        "\n",
        "def load_live(base_dir, filter=False):\n",
        "    data_path = os.path.join(base_dir, 'dmos_with_names.csv')\n",
        "    data = pd.read_csv(data_path, index_col=False)\n",
        "    if filter:\n",
        "      distortion_types = [1, 2, 3, 4] # filter distortions: jp2k, jpeg, wn and blur\n",
        "      data = data[data['image_filename'].apply(lambda x: int(x.split('_')[1]) in distortion_types)]\n",
        "    return data\n",
        "\n",
        "def split_data(data1, data2=None, params=None, cross=False):\n",
        "    train_data, test_data = train_test_split(data1, test_size=0.2, random_state=40)\n",
        "    train_data, val_data = train_test_split(train_data, test_size=0.25, random_state=40)\n",
        "    return train_data, val_data, test_data\n",
        "\n",
        "live_dir = 'LIVE'\n",
        "db_dir = live_dir\n",
        "score_measure = 'DMOS'\n",
        "\n",
        "data_live = load_live(live_dir, filter=False)\n",
        "data_live.to_csv('LIVE/dmos_with_names.csv', index=False)\n",
        "data = data_live\n",
        "\n",
        "train_data, val_data, test_data = split_data(data)\n",
        "normalize_and_slice(db_dir, train_data, val_data, test_data)\n",
        "\n",
        "train_data = pd.read_csv(f'{db_dir}/normalized_distorted_images/training/patch_training.csv')\n",
        "val_data = pd.read_csv(f'{db_dir}/normalized_distorted_images/validation/patch_validation.csv')\n",
        "test_data = pd.read_csv(f'{db_dir}/normalized_distorted_images/test/patch_test.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRTC9VST0kKU",
        "outputId": "31ba0d8c-7500-4474-bd37-329552b81793"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[training]: Saved full normalized distorted image info to:\n",
            "LIVE/normalized_distorted_images/training/patch_training.csv.\n",
            "[training]: Saved patch info to LIVE/normalized_distorted_images/training/patch_training.csv.\n",
            "[validation]: Saved full normalized distorted image info to:\n",
            "LIVE/normalized_distorted_images/validation/patch_validation.csv.\n",
            "[validation]: Saved patch info to LIVE/normalized_distorted_images/validation/patch_validation.csv.\n",
            "[test]: Saved full normalized distorted image info to:\n",
            "LIVE/normalized_distorted_images/test/patch_test.csv.\n",
            "[test]: Saved patch info to LIVE/normalized_distorted_images/test/patch_test.csv.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "dataframes = [train_data, val_data, test_data]\n",
        "\n",
        "for i in range(len(dataframes)):\n",
        "  my_dists = dataframes[i]['Distortion']\n",
        "  le = LabelEncoder()\n",
        "  y_train_class_encoded = le.fit_transform(my_dists)\n",
        "  my_dists_one_hot = to_categorical(y_train_class_encoded, num_classes=5)\n",
        "  one_hot_df = pd.DataFrame(my_dists_one_hot, columns = [\"Distortion_\"+str(int(j)) for j in range(my_dists_one_hot.shape[1])])\n",
        "\n",
        "  # Concatenate the one-hot encoded dataframe with your original dataframe\n",
        "  dataframes[i] = pd.concat([dataframes[i], one_hot_df], axis=1)\n",
        "\n",
        "  # If you want to drop the original 'Distortion' column\n",
        "  dataframes[i] = dataframes[i].drop(['Distortion'], axis=1)\n",
        "\n",
        "# Now, your dataframes are one-hot encoded and the original 'Distortion' column is dropped.\n",
        "train_data, val_data, test_data = dataframes"
      ],
      "metadata": {
        "id": "m_ZHw4484nPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "# Function to create a single column with one-hot encoded numpy arrays with integer values\n",
        "def encode_distortion(dataframes):\n",
        "    for i in range(len(dataframes)):\n",
        "        my_dists = dataframes[i]['Distortion']\n",
        "        le = LabelEncoder()\n",
        "        y_class_encoded = le.fit_transform(my_dists)\n",
        "        my_dists_one_hot = to_categorical(y_class_encoded, num_classes=5).astype(int)\n",
        "        # Assign to a new column as numpy arrays\n",
        "        dataframes[i]['Distortion_encoded'] = [np.array(one_hot) for one_hot in my_dists_one_hot]\n",
        "        # Drop the original 'Distortion' column\n",
        "        dataframes[i] = dataframes[i].drop(['Distortion'], axis=1)\n",
        "    return dataframes\n",
        "\n",
        "# Apply the function to the dataframes\n",
        "train_data, val_data, test_data = encode_distortion([train_data, val_data, test_data])"
      ],
      "metadata": {
        "id": "VqXOCUG0LudM"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "0jDEOGTkBSeI",
        "outputId": "3e9f8442-ebc6-4d06-b697-7a2796ec85d8"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     image_filename       DMOS Distortion_encoded\n",
              "0  NORM_lighthouse2_4_5_patch_0.bmp  24.912864    [0, 1, 0, 0, 0]\n",
              "1  NORM_lighthouse2_4_5_patch_1.bmp  24.912864    [0, 1, 0, 0, 0]\n",
              "2  NORM_lighthouse2_4_5_patch_2.bmp  24.912864    [0, 1, 0, 0, 0]\n",
              "3  NORM_lighthouse2_4_5_patch_3.bmp  24.912864    [0, 1, 0, 0, 0]\n",
              "4  NORM_lighthouse2_4_5_patch_4.bmp  24.912864    [0, 1, 0, 0, 0]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f5d232d4-e826-494f-80b9-faf84d85f411\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_filename</th>\n",
              "      <th>DMOS</th>\n",
              "      <th>Distortion_encoded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NORM_lighthouse2_4_5_patch_0.bmp</td>\n",
              "      <td>24.912864</td>\n",
              "      <td>[0, 1, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NORM_lighthouse2_4_5_patch_1.bmp</td>\n",
              "      <td>24.912864</td>\n",
              "      <td>[0, 1, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NORM_lighthouse2_4_5_patch_2.bmp</td>\n",
              "      <td>24.912864</td>\n",
              "      <td>[0, 1, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NORM_lighthouse2_4_5_patch_3.bmp</td>\n",
              "      <td>24.912864</td>\n",
              "      <td>[0, 1, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NORM_lighthouse2_4_5_patch_4.bmp</td>\n",
              "      <td>24.912864</td>\n",
              "      <td>[0, 1, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f5d232d4-e826-494f-80b9-faf84d85f411')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f5d232d4-e826-494f-80b9-faf84d85f411 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f5d232d4-e826-494f-80b9-faf84d85f411');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-47dea161-e8cb-4df4-890d-ba29d62cef9b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-47dea161-e8cb-4df4-890d-ba29d62cef9b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-47dea161-e8cb-4df4-890d-ba29d62cef9b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_data",
              "summary": "{\n  \"name\": \"test_data\",\n  \"rows\": 53332,\n  \"fields\": [\n    {\n      \"column\": \"image_filename\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 53332,\n        \"samples\": [\n          \"NORM_paintedhouse_5_2_patch_262.bmp\",\n          \"NORM_sailing1_4_4_patch_0.bmp\",\n          \"NORM_woman_4_4_patch_310.bmp\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DMOS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 27.126621925827592,\n        \"min\": 3.21426394370199,\n        \"max\": 107.650330777516,\n        \"num_unique_values\": 156,\n        \"samples\": [\n          28.1809128723087,\n          54.373331274324,\n          3.21426394370199\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Distortion_encoded\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "help(ImageDataGenerator.flow_from_dataframe)"
      ],
      "metadata": {
        "id": "ZR89d3PYjaJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "def create_data_generators(base_dir, train_data, val_data, test_data, batch_size):\n",
        "    datagen = ImageDataGenerator()\n",
        "    train_generator = datagen.flow_from_dataframe(\n",
        "        dataframe=train_data,\n",
        "        directory=os.path.join(base_dir, 'training/patches/'),\n",
        "        x_col='image_filename',\n",
        "        y_col=['DMOS', 'Distortion_encoded'],\n",
        "        target_size=(32, 32),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='multi_output',\n",
        "        shuffle=True,\n",
        "        seed=42\n",
        "    )\n",
        "    val_generator = datagen.flow_from_dataframe(\n",
        "        dataframe=val_data,\n",
        "        directory=os.path.join(base_dir, 'validation/patches/'),\n",
        "        x_col='image_filename',\n",
        "        y_col=['DMOS', 'Distortion_encoded'],\n",
        "        target_size=(32, 32),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='multi_output',\n",
        "        shuffle=True,\n",
        "        seed=42\n",
        "    )\n",
        "    test_generator = datagen.flow_from_dataframe(\n",
        "        dataframe=test_data,\n",
        "        directory=os.path.join(base_dir, 'test/patches/'),\n",
        "        x_col='image_filename',\n",
        "        y_col=['DMOS', 'Distortion_encoded'],\n",
        "        target_size=(32, 32),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='multi_output',\n",
        "        shuffle=False,\n",
        "        seed=42\n",
        "    )\n",
        "    return train_generator, val_generator, test_generator\n",
        "\n",
        "# Define file paths\n",
        "base_dir = 'LIVE/normalized_distorted_images'\n",
        "# Create generators\n",
        "train_generator, val_generator, test_generator = create_data_generators(base_dir, train_data, val_data, test_data, batch_size=32)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lb0f_240hRCI",
        "outputId": "00bd4e32-11ef-43f2-f1d5-f2af258a8e6a"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 161332 validated image filenames.\n",
            "Found 53196 validated image filenames.\n",
            "Found 53332 validated image filenames.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Conv2D, GlobalMaxPooling2D, Dense, Dropout, Input\n",
        "\n",
        "# Define the model\n",
        "input_shape = (32, 32, 3)\n",
        "\n",
        "inputs = tf.keras.layers.Input(shape=input_shape)\n",
        "x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu')(inputs)\n",
        "x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
        "x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
        "x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
        "x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu')(x)\n",
        "x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
        "\n",
        "dmos_output = tf.keras.layers.Dense(1, name='dmos')(x)\n",
        "distortion_output = tf.keras.layers.Dense(5, activation='softmax', name='distortion')(x)\n",
        "\n",
        "model = tf.keras.models.Model(inputs=inputs, outputs=[dmos_output, distortion_output])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss={'dmos': 'mse', 'distortion': 'categorical_crossentropy'},\n",
        "              metrics={'dmos': 'mse', 'distortion': 'accuracy'})"
      ],
      "metadata": {
        "id": "BHFIk0tcgjho"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_generator, epochs=10, validation_data=val_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWSNepa3hpXw",
        "outputId": "ff808461-5036-4b19-c653-0521588f2a66"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "5042/5042 [==============================] - 1658s 328ms/step - loss: 268.0976 - dmos_loss: 266.9870 - distortion_loss: 1.1106 - dmos_mse: 266.9870 - distortion_accuracy: 0.4954 - val_loss: 339.7514 - val_dmos_loss: 338.7859 - val_distortion_loss: 0.9651 - val_dmos_mse: 338.7859 - val_distortion_accuracy: 0.5537\n",
            "Epoch 2/10\n",
            "5042/5042 [==============================] - 1694s 336ms/step - loss: 186.4554 - dmos_loss: 185.5819 - distortion_loss: 0.8738 - dmos_mse: 185.5819 - distortion_accuracy: 0.5942 - val_loss: 270.9374 - val_dmos_loss: 270.0068 - val_distortion_loss: 0.9304 - val_dmos_mse: 270.0068 - val_distortion_accuracy: 0.5746\n",
            "Epoch 3/10\n",
            "5042/5042 [==============================] - 1701s 337ms/step - loss: 171.0876 - dmos_loss: 170.3115 - distortion_loss: 0.7758 - dmos_mse: 170.3115 - distortion_accuracy: 0.6502 - val_loss: 258.0150 - val_dmos_loss: 257.1908 - val_distortion_loss: 0.8246 - val_dmos_mse: 257.1908 - val_distortion_accuracy: 0.6293\n",
            "Epoch 4/10\n",
            "5042/5042 [==============================] - 1676s 332ms/step - loss: 160.9440 - dmos_loss: 160.2336 - distortion_loss: 0.7106 - dmos_mse: 160.2336 - distortion_accuracy: 0.6871 - val_loss: 252.7856 - val_dmos_loss: 251.9895 - val_distortion_loss: 0.7961 - val_dmos_mse: 251.9895 - val_distortion_accuracy: 0.6612\n",
            "Epoch 5/10\n",
            "5042/5042 [==============================] - 1643s 326ms/step - loss: 153.0369 - dmos_loss: 152.3566 - distortion_loss: 0.6803 - dmos_mse: 152.3566 - distortion_accuracy: 0.7004 - val_loss: 265.6722 - val_dmos_loss: 264.9056 - val_distortion_loss: 0.7670 - val_dmos_mse: 264.9056 - val_distortion_accuracy: 0.6621\n",
            "Epoch 6/10\n",
            "5042/5042 [==============================] - 1748s 347ms/step - loss: 146.0366 - dmos_loss: 145.3797 - distortion_loss: 0.6570 - dmos_mse: 145.3797 - distortion_accuracy: 0.7122 - val_loss: 268.9414 - val_dmos_loss: 268.1485 - val_distortion_loss: 0.7928 - val_dmos_mse: 268.1485 - val_distortion_accuracy: 0.6603\n",
            "Epoch 7/10\n",
            "5042/5042 [==============================] - 1705s 338ms/step - loss: 140.8577 - dmos_loss: 140.2117 - distortion_loss: 0.6460 - dmos_mse: 140.2117 - distortion_accuracy: 0.7185 - val_loss: 266.2635 - val_dmos_loss: 265.5204 - val_distortion_loss: 0.7432 - val_dmos_mse: 265.5204 - val_distortion_accuracy: 0.6722\n",
            "Epoch 8/10\n",
            "5042/5042 [==============================] - 1816s 360ms/step - loss: 134.2988 - dmos_loss: 133.6639 - distortion_loss: 0.6344 - dmos_mse: 133.6639 - distortion_accuracy: 0.7234 - val_loss: 258.6607 - val_dmos_loss: 257.9444 - val_distortion_loss: 0.7163 - val_dmos_mse: 257.9444 - val_distortion_accuracy: 0.6898\n",
            "Epoch 9/10\n",
            "5042/5042 [==============================] - 1664s 330ms/step - loss: 128.8855 - dmos_loss: 128.2566 - distortion_loss: 0.6289 - dmos_mse: 128.2566 - distortion_accuracy: 0.7254 - val_loss: 255.6406 - val_dmos_loss: 254.8632 - val_distortion_loss: 0.7775 - val_dmos_mse: 254.8632 - val_distortion_accuracy: 0.6727\n",
            "Epoch 10/10\n",
            "5042/5042 [==============================] - 1855s 368ms/step - loss: 122.4442 - dmos_loss: 121.8216 - distortion_loss: 0.6226 - dmos_mse: 121.8216 - distortion_accuracy: 0.7298 - val_loss: 258.7113 - val_dmos_loss: 257.9673 - val_distortion_loss: 0.7442 - val_dmos_mse: 257.9673 - val_distortion_accuracy: 0.6748\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "help(tf.keras.models.Model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "XLPy7yZfK41j",
        "outputId": "ad518e91-f635-4a61-886a-6e06b048b63d"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on class Model in module keras.src.engine.training:\n",
            "\n",
            "class Model(keras.src.engine.base_layer.Layer, keras.src.utils.version_utils.ModelVersionSelector)\n",
            " |  Model(*args, **kwargs)\n",
            " |  \n",
            " |  A model grouping layers into an object with training/inference features.\n",
            " |  \n",
            " |  Args:\n",
            " |      inputs: The input(s) of the model: a `keras.Input` object or a\n",
            " |          combination of `keras.Input` objects in a dict, list or tuple.\n",
            " |      outputs: The output(s) of the model: a tensor that originated from\n",
            " |          `keras.Input` objects or a combination of such tensors in a dict,\n",
            " |          list or tuple. See Functional API example below.\n",
            " |      name: String, the name of the model.\n",
            " |  \n",
            " |  There are two ways to instantiate a `Model`:\n",
            " |  \n",
            " |  1 - With the \"Functional API\", where you start from `Input`,\n",
            " |  you chain layer calls to specify the model's forward pass,\n",
            " |  and finally you create your model from inputs and outputs:\n",
            " |  \n",
            " |  ```python\n",
            " |  import tensorflow as tf\n",
            " |  \n",
            " |  inputs = tf.keras.Input(shape=(3,))\n",
            " |  x = tf.keras.layers.Dense(4, activation=tf.nn.relu)(inputs)\n",
            " |  outputs = tf.keras.layers.Dense(5, activation=tf.nn.softmax)(x)\n",
            " |  model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
            " |  ```\n",
            " |  \n",
            " |  Note: Only dicts, lists, and tuples of input tensors are supported. Nested\n",
            " |  inputs are not supported (e.g. lists of list or dicts of dict).\n",
            " |  \n",
            " |  A new Functional API model can also be created by using the\n",
            " |  intermediate tensors. This enables you to quickly extract sub-components\n",
            " |  of the model.\n",
            " |  \n",
            " |  Example:\n",
            " |  \n",
            " |  ```python\n",
            " |  inputs = keras.Input(shape=(None, None, 3))\n",
            " |  processed = keras.layers.RandomCrop(width=32, height=32)(inputs)\n",
            " |  conv = keras.layers.Conv2D(filters=2, kernel_size=3)(processed)\n",
            " |  pooling = keras.layers.GlobalAveragePooling2D()(conv)\n",
            " |  feature = keras.layers.Dense(10)(pooling)\n",
            " |  \n",
            " |  full_model = keras.Model(inputs, feature)\n",
            " |  backbone = keras.Model(processed, conv)\n",
            " |  activations = keras.Model(conv, feature)\n",
            " |  ```\n",
            " |  \n",
            " |  Note that the `backbone` and `activations` models are not\n",
            " |  created with `keras.Input` objects, but with the tensors that are originated\n",
            " |  from `keras.Input` objects. Under the hood, the layers and weights will\n",
            " |  be shared across these models, so that user can train the `full_model`, and\n",
            " |  use `backbone` or `activations` to do feature extraction.\n",
            " |  The inputs and outputs of the model can be nested structures of tensors as\n",
            " |  well, and the created models are standard Functional API models that support\n",
            " |  all the existing APIs.\n",
            " |  \n",
            " |  2 - By subclassing the `Model` class: in that case, you should define your\n",
            " |  layers in `__init__()` and you should implement the model's forward pass\n",
            " |  in `call()`.\n",
            " |  \n",
            " |  ```python\n",
            " |  import tensorflow as tf\n",
            " |  \n",
            " |  class MyModel(tf.keras.Model):\n",
            " |  \n",
            " |    def __init__(self):\n",
            " |      super().__init__()\n",
            " |      self.dense1 = tf.keras.layers.Dense(4, activation=tf.nn.relu)\n",
            " |      self.dense2 = tf.keras.layers.Dense(5, activation=tf.nn.softmax)\n",
            " |  \n",
            " |    def call(self, inputs):\n",
            " |      x = self.dense1(inputs)\n",
            " |      return self.dense2(x)\n",
            " |  \n",
            " |  model = MyModel()\n",
            " |  ```\n",
            " |  \n",
            " |  If you subclass `Model`, you can optionally have\n",
            " |  a `training` argument (boolean) in `call()`, which you can use to specify\n",
            " |  a different behavior in training and inference:\n",
            " |  \n",
            " |  ```python\n",
            " |  import tensorflow as tf\n",
            " |  \n",
            " |  class MyModel(tf.keras.Model):\n",
            " |  \n",
            " |    def __init__(self):\n",
            " |      super().__init__()\n",
            " |      self.dense1 = tf.keras.layers.Dense(4, activation=tf.nn.relu)\n",
            " |      self.dense2 = tf.keras.layers.Dense(5, activation=tf.nn.softmax)\n",
            " |      self.dropout = tf.keras.layers.Dropout(0.5)\n",
            " |  \n",
            " |    def call(self, inputs, training=False):\n",
            " |      x = self.dense1(inputs)\n",
            " |      if training:\n",
            " |        x = self.dropout(x, training=training)\n",
            " |      return self.dense2(x)\n",
            " |  \n",
            " |  model = MyModel()\n",
            " |  ```\n",
            " |  \n",
            " |  Once the model is created, you can config the model with losses and metrics\n",
            " |  with `model.compile()`, train the model with `model.fit()`, or use the model\n",
            " |  to do prediction with `model.predict()`.\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      Model\n",
            " |      keras.src.engine.base_layer.Layer\n",
            " |      tensorflow.python.module.module.Module\n",
            " |      tensorflow.python.trackable.autotrackable.AutoTrackable\n",
            " |      tensorflow.python.trackable.base.Trackable\n",
            " |      keras.src.utils.version_utils.LayerVersionSelector\n",
            " |      keras.src.utils.version_utils.ModelVersionSelector\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __call__(self, *args, **kwargs)\n",
            " |  \n",
            " |  __copy__(self)\n",
            " |  \n",
            " |  __deepcopy__(self, memo)\n",
            " |  \n",
            " |  __init__(self, *args, **kwargs)\n",
            " |  \n",
            " |  __reduce__(self)\n",
            " |      Helper for pickle.\n",
            " |  \n",
            " |  __setattr__(self, name, value)\n",
            " |      Support self.foo = trackable syntax.\n",
            " |  \n",
            " |  build(self, input_shape)\n",
            " |      Builds the model based on input shapes received.\n",
            " |      \n",
            " |      This is to be used for subclassed models, which do not know at\n",
            " |      instantiation time what their inputs look like.\n",
            " |      \n",
            " |      This method only exists for users who want to call `model.build()` in a\n",
            " |      standalone way (as a substitute for calling the model on real data to\n",
            " |      build it). It will never be called by the framework (and thus it will\n",
            " |      never throw unexpected errors in an unrelated workflow).\n",
            " |      \n",
            " |      Args:\n",
            " |       input_shape: Single tuple, `TensorShape` instance, or list/dict of\n",
            " |         shapes, where shapes are tuples, integers, or `TensorShape`\n",
            " |         instances.\n",
            " |      \n",
            " |      Raises:\n",
            " |        ValueError:\n",
            " |          1. In case of invalid user-provided data (not of type tuple,\n",
            " |             list, `TensorShape`, or dict).\n",
            " |          2. If the model requires call arguments that are agnostic\n",
            " |             to the input shapes (positional or keyword arg in call\n",
            " |             signature).\n",
            " |          3. If not all layers were properly built.\n",
            " |          4. If float type inputs are not supported within the layers.\n",
            " |      \n",
            " |        In each of these cases, the user should build their model by calling\n",
            " |        it on real tensor data.\n",
            " |  \n",
            " |  call(self, inputs, training=None, mask=None)\n",
            " |      Calls the model on new inputs and returns the outputs as tensors.\n",
            " |      \n",
            " |      In this case `call()` just reapplies\n",
            " |      all ops in the graph to the new inputs\n",
            " |      (e.g. build a new computational graph from the provided inputs).\n",
            " |      \n",
            " |      Note: This method should not be called directly. It is only meant to be\n",
            " |      overridden when subclassing `tf.keras.Model`.\n",
            " |      To call a model on an input, always use the `__call__()` method,\n",
            " |      i.e. `model(inputs)`, which relies on the underlying `call()` method.\n",
            " |      \n",
            " |      Args:\n",
            " |          inputs: Input tensor, or dict/list/tuple of input tensors.\n",
            " |          training: Boolean or boolean scalar tensor, indicating whether to\n",
            " |            run the `Network` in training mode or inference mode.\n",
            " |          mask: A mask or list of masks. A mask can be either a boolean tensor\n",
            " |            or None (no mask). For more details, check the guide\n",
            " |            [here](https://www.tensorflow.org/guide/keras/masking_and_padding).\n",
            " |      \n",
            " |      Returns:\n",
            " |          A tensor if there is a single output, or\n",
            " |          a list of tensors if there are more than one outputs.\n",
            " |  \n",
            " |  compile(self, optimizer='rmsprop', loss=None, metrics=None, loss_weights=None, weighted_metrics=None, run_eagerly=None, steps_per_execution=None, jit_compile=None, pss_evaluation_shards=0, **kwargs)\n",
            " |      Configures the model for training.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
            " |                    loss=tf.keras.losses.BinaryCrossentropy(),\n",
            " |                    metrics=[tf.keras.metrics.BinaryAccuracy(),\n",
            " |                             tf.keras.metrics.FalseNegatives()])\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |          optimizer: String (name of optimizer) or optimizer instance. See\n",
            " |            `tf.keras.optimizers`.\n",
            " |          loss: Loss function. May be a string (name of loss function), or\n",
            " |            a `tf.keras.losses.Loss` instance. See `tf.keras.losses`. A loss\n",
            " |            function is any callable with the signature `loss = fn(y_true,\n",
            " |            y_pred)`, where `y_true` are the ground truth values, and\n",
            " |            `y_pred` are the model's predictions.\n",
            " |            `y_true` should have shape\n",
            " |            `(batch_size, d0, .. dN)` (except in the case of\n",
            " |            sparse loss functions such as\n",
            " |            sparse categorical crossentropy which expects integer arrays of\n",
            " |            shape `(batch_size, d0, .. dN-1)`).\n",
            " |            `y_pred` should have shape `(batch_size, d0, .. dN)`.\n",
            " |            The loss function should return a float tensor.\n",
            " |            If a custom `Loss` instance is\n",
            " |            used and reduction is set to `None`, return value has shape\n",
            " |            `(batch_size, d0, .. dN-1)` i.e. per-sample or per-timestep loss\n",
            " |            values; otherwise, it is a scalar. If the model has multiple\n",
            " |            outputs, you can use a different loss on each output by passing a\n",
            " |            dictionary or a list of losses. The loss value that will be\n",
            " |            minimized by the model will then be the sum of all individual\n",
            " |            losses, unless `loss_weights` is specified.\n",
            " |          metrics: List of metrics to be evaluated by the model during\n",
            " |            training and testing. Each of this can be a string (name of a\n",
            " |            built-in function), function or a `tf.keras.metrics.Metric`\n",
            " |            instance. See `tf.keras.metrics`. Typically you will use\n",
            " |            `metrics=['accuracy']`.\n",
            " |            A function is any callable with the signature `result = fn(y_true,\n",
            " |            y_pred)`. To specify different metrics for different outputs of a\n",
            " |            multi-output model, you could also pass a dictionary, such as\n",
            " |            `metrics={'output_a':'accuracy', 'output_b':['accuracy', 'mse']}`.\n",
            " |            You can also pass a list to specify a metric or a list of metrics\n",
            " |            for each output, such as\n",
            " |            `metrics=[['accuracy'], ['accuracy', 'mse']]`\n",
            " |            or `metrics=['accuracy', ['accuracy', 'mse']]`. When you pass the\n",
            " |            strings 'accuracy' or 'acc', we convert this to one of\n",
            " |            `tf.keras.metrics.BinaryAccuracy`,\n",
            " |            `tf.keras.metrics.CategoricalAccuracy`,\n",
            " |            `tf.keras.metrics.SparseCategoricalAccuracy` based on the shapes\n",
            " |            of the targets and of the model output. We do a similar\n",
            " |            conversion for the strings 'crossentropy' and 'ce' as well.\n",
            " |            The metrics passed here are evaluated without sample weighting; if\n",
            " |            you would like sample weighting to apply, you can specify your\n",
            " |            metrics via the `weighted_metrics` argument instead.\n",
            " |          loss_weights: Optional list or dictionary specifying scalar\n",
            " |            coefficients (Python floats) to weight the loss contributions of\n",
            " |            different model outputs. The loss value that will be minimized by\n",
            " |            the model will then be the *weighted sum* of all individual\n",
            " |            losses, weighted by the `loss_weights` coefficients.  If a list,\n",
            " |            it is expected to have a 1:1 mapping to the model's outputs. If a\n",
            " |            dict, it is expected to map output names (strings) to scalar\n",
            " |            coefficients.\n",
            " |          weighted_metrics: List of metrics to be evaluated and weighted by\n",
            " |            `sample_weight` or `class_weight` during training and testing.\n",
            " |          run_eagerly: Bool. If `True`, this `Model`'s logic will not be\n",
            " |            wrapped in a `tf.function`. Recommended to leave this as `None`\n",
            " |            unless your `Model` cannot be run inside a `tf.function`.\n",
            " |            `run_eagerly=True` is not supported when using\n",
            " |            `tf.distribute.experimental.ParameterServerStrategy`. Defaults to\n",
            " |             `False`.\n",
            " |          steps_per_execution: Int or `'auto'`. The number of batches to\n",
            " |            run during each `tf.function` call. If set to \"auto\", keras will\n",
            " |            automatically tune `steps_per_execution` during runtime. Running\n",
            " |            multiple batches inside a single `tf.function` call can greatly\n",
            " |            improve performance on TPUs, when used with distributed strategies\n",
            " |            such as `ParameterServerStrategy`, or with small models with a\n",
            " |            large Python overhead. At most, one full epoch will be run each\n",
            " |            execution. If a number larger than the size of the epoch is\n",
            " |            passed, the execution will be truncated to the size of the epoch.\n",
            " |            Note that if `steps_per_execution` is set to `N`,\n",
            " |            `Callback.on_batch_begin` and `Callback.on_batch_end` methods will\n",
            " |            only be called every `N` batches (i.e. before/after each\n",
            " |            `tf.function` execution). Defaults to `1`.\n",
            " |          jit_compile: If `True`, compile the model training step with XLA.\n",
            " |            [XLA](https://www.tensorflow.org/xla) is an optimizing compiler\n",
            " |            for machine learning.\n",
            " |            `jit_compile` is not enabled for by default.\n",
            " |            Note that `jit_compile=True`\n",
            " |            may not necessarily work for all models.\n",
            " |            For more information on supported operations please refer to the\n",
            " |            [XLA documentation](https://www.tensorflow.org/xla).\n",
            " |            Also refer to\n",
            " |            [known XLA issues](https://www.tensorflow.org/xla/known_issues)\n",
            " |            for more details.\n",
            " |          pss_evaluation_shards: Integer or 'auto'. Used for\n",
            " |            `tf.distribute.ParameterServerStrategy` training only. This arg\n",
            " |            sets the number of shards to split the dataset into, to enable an\n",
            " |            exact visitation guarantee for evaluation, meaning the model will\n",
            " |            be applied to each dataset element exactly once, even if workers\n",
            " |            fail. The dataset must be sharded to ensure separate workers do\n",
            " |            not process the same data. The number of shards should be at least\n",
            " |            the number of workers for good performance. A value of 'auto'\n",
            " |            turns on exact evaluation and uses a heuristic for the number of\n",
            " |            shards based on the number of workers. 0, meaning no\n",
            " |            visitation guarantee is provided. NOTE: Custom implementations of\n",
            " |            `Model.test_step` will be ignored when doing exact evaluation.\n",
            " |            Defaults to `0`.\n",
            " |          **kwargs: Arguments supported for backwards compatibility only.\n",
            " |  \n",
            " |  compile_from_config(self, config)\n",
            " |      Compiles the model with the information given in config.\n",
            " |      \n",
            " |      This method uses the information in the config (optimizer, loss,\n",
            " |      metrics, etc.) to compile the model.\n",
            " |      \n",
            " |      Args:\n",
            " |          config: Dict containing information for compiling the model.\n",
            " |  \n",
            " |  compute_loss(self, x=None, y=None, y_pred=None, sample_weight=None)\n",
            " |      Compute the total loss, validate it, and return it.\n",
            " |      \n",
            " |      Subclasses can optionally override this method to provide custom loss\n",
            " |      computation logic.\n",
            " |      \n",
            " |      Example:\n",
            " |      ```python\n",
            " |      class MyModel(tf.keras.Model):\n",
            " |      \n",
            " |        def __init__(self, *args, **kwargs):\n",
            " |          super(MyModel, self).__init__(*args, **kwargs)\n",
            " |          self.loss_tracker = tf.keras.metrics.Mean(name='loss')\n",
            " |      \n",
            " |        def compute_loss(self, x, y, y_pred, sample_weight):\n",
            " |          loss = tf.reduce_mean(tf.math.squared_difference(y_pred, y))\n",
            " |          loss += tf.add_n(self.losses)\n",
            " |          self.loss_tracker.update_state(loss)\n",
            " |          return loss\n",
            " |      \n",
            " |        def reset_metrics(self):\n",
            " |          self.loss_tracker.reset_states()\n",
            " |      \n",
            " |        @property\n",
            " |        def metrics(self):\n",
            " |          return [self.loss_tracker]\n",
            " |      \n",
            " |      tensors = tf.random.uniform((10, 10)), tf.random.uniform((10,))\n",
            " |      dataset = tf.data.Dataset.from_tensor_slices(tensors).repeat().batch(1)\n",
            " |      \n",
            " |      inputs = tf.keras.layers.Input(shape=(10,), name='my_input')\n",
            " |      outputs = tf.keras.layers.Dense(10)(inputs)\n",
            " |      model = MyModel(inputs, outputs)\n",
            " |      model.add_loss(tf.reduce_sum(outputs))\n",
            " |      \n",
            " |      optimizer = tf.keras.optimizers.SGD()\n",
            " |      model.compile(optimizer, loss='mse', steps_per_execution=10)\n",
            " |      model.fit(dataset, epochs=2, steps_per_epoch=10)\n",
            " |      print('My custom loss: ', model.loss_tracker.result().numpy())\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |        x: Input data.\n",
            " |        y: Target data.\n",
            " |        y_pred: Predictions returned by the model (output of `model(x)`)\n",
            " |        sample_weight: Sample weights for weighting the loss function.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The total loss as a `tf.Tensor`, or `None` if no loss results (which\n",
            " |        is the case when called by `Model.test_step`).\n",
            " |  \n",
            " |  compute_metrics(self, x, y, y_pred, sample_weight)\n",
            " |      Update metric states and collect all metrics to be returned.\n",
            " |      \n",
            " |      Subclasses can optionally override this method to provide custom metric\n",
            " |      updating and collection logic.\n",
            " |      \n",
            " |      Example:\n",
            " |      ```python\n",
            " |      class MyModel(tf.keras.Sequential):\n",
            " |      \n",
            " |        def compute_metrics(self, x, y, y_pred, sample_weight):\n",
            " |      \n",
            " |          # This super call updates `self.compiled_metrics` and returns\n",
            " |          # results for all metrics listed in `self.metrics`.\n",
            " |          metric_results = super(MyModel, self).compute_metrics(\n",
            " |              x, y, y_pred, sample_weight)\n",
            " |      \n",
            " |          # Note that `self.custom_metric` is not listed in `self.metrics`.\n",
            " |          self.custom_metric.update_state(x, y, y_pred, sample_weight)\n",
            " |          metric_results['custom_metric_name'] = self.custom_metric.result()\n",
            " |          return metric_results\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |        x: Input data.\n",
            " |        y: Target data.\n",
            " |        y_pred: Predictions returned by the model (output of `model.call(x)`)\n",
            " |        sample_weight: Sample weights for weighting the loss function.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `dict` containing values that will be passed to\n",
            " |        `tf.keras.callbacks.CallbackList.on_train_batch_end()`. Typically, the\n",
            " |        values of the metrics listed in `self.metrics` are returned. Example:\n",
            " |        `{'loss': 0.2, 'accuracy': 0.7}`.\n",
            " |  \n",
            " |  evaluate(self, x=None, y=None, batch_size=None, verbose='auto', sample_weight=None, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, return_dict=False, **kwargs)\n",
            " |      Returns the loss value & metrics values for the model in test mode.\n",
            " |      \n",
            " |      Computation is done in batches (see the `batch_size` arg.)\n",
            " |      \n",
            " |      Args:\n",
            " |          x: Input data. It could be:\n",
            " |            - A Numpy array (or array-like), or a list of arrays\n",
            " |              (in case the model has multiple inputs).\n",
            " |            - A TensorFlow tensor, or a list of tensors\n",
            " |              (in case the model has multiple inputs).\n",
            " |            - A dict mapping input names to the corresponding array/tensors,\n",
            " |              if the model has named inputs.\n",
            " |            - A `tf.data` dataset. Should return a tuple\n",
            " |              of either `(inputs, targets)` or\n",
            " |              `(inputs, targets, sample_weights)`.\n",
            " |            - A generator or `keras.utils.Sequence` returning `(inputs,\n",
            " |              targets)` or `(inputs, targets, sample_weights)`.\n",
            " |            A more detailed description of unpacking behavior for iterator\n",
            " |            types (Dataset, generator, Sequence) is given in the `Unpacking\n",
            " |            behavior for iterator-like inputs` section of `Model.fit`.\n",
            " |          y: Target data. Like the input data `x`, it could be either Numpy\n",
            " |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
            " |            (you cannot have Numpy inputs and tensor targets, or inversely).\n",
            " |            If `x` is a dataset, generator or `keras.utils.Sequence` instance,\n",
            " |            `y` should not be specified (since targets will be obtained from\n",
            " |            the iterator/dataset).\n",
            " |          batch_size: Integer or `None`. Number of samples per batch of\n",
            " |            computation. If unspecified, `batch_size` will default to 32. Do\n",
            " |            not specify the `batch_size` if your data is in the form of a\n",
            " |            dataset, generators, or `keras.utils.Sequence` instances (since\n",
            " |            they generate batches).\n",
            " |          verbose: `\"auto\"`, 0, 1, or 2. Verbosity mode.\n",
            " |              0 = silent, 1 = progress bar, 2 = single line.\n",
            " |              `\"auto\"` becomes 1 for most cases, and to 2 when used with\n",
            " |              `ParameterServerStrategy`. Note that the progress bar is not\n",
            " |              particularly useful when logged to a file, so `verbose=2` is\n",
            " |              recommended when not running interactively (e.g. in a production\n",
            " |              environment). Defaults to 'auto'.\n",
            " |          sample_weight: Optional Numpy array of weights for the test samples,\n",
            " |            used for weighting the loss function. You can either pass a flat\n",
            " |            (1D) Numpy array with the same length as the input samples\n",
            " |              (1:1 mapping between weights and samples), or in the case of\n",
            " |                temporal data, you can pass a 2D array with shape `(samples,\n",
            " |                sequence_length)`, to apply a different weight to every\n",
            " |                timestep of every sample. This argument is not supported when\n",
            " |                `x` is a dataset, instead pass sample weights as the third\n",
            " |                element of `x`.\n",
            " |          steps: Integer or `None`. Total number of steps (batches of samples)\n",
            " |            before declaring the evaluation round finished. Ignored with the\n",
            " |            default value of `None`. If x is a `tf.data` dataset and `steps`\n",
            " |            is None, 'evaluate' will run until the dataset is exhausted. This\n",
            " |            argument is not supported with array inputs.\n",
            " |          callbacks: List of `keras.callbacks.Callback` instances. List of\n",
            " |            callbacks to apply during evaluation. See\n",
            " |            [callbacks](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks).\n",
            " |          max_queue_size: Integer. Used for generator or\n",
            " |            `keras.utils.Sequence` input only. Maximum size for the generator\n",
            " |            queue. If unspecified, `max_queue_size` will default to 10.\n",
            " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
            " |            only. Maximum number of processes to spin up when using\n",
            " |            process-based threading. If unspecified, `workers` will default to\n",
            " |            1.\n",
            " |          use_multiprocessing: Boolean. Used for generator or\n",
            " |            `keras.utils.Sequence` input only. If `True`, use process-based\n",
            " |            threading. If unspecified, `use_multiprocessing` will default to\n",
            " |            `False`. Note that because this implementation relies on\n",
            " |            multiprocessing, you should not pass non-pickleable arguments to\n",
            " |            the generator as they can't be passed easily to children\n",
            " |            processes.\n",
            " |          return_dict: If `True`, loss and metric results are returned as a\n",
            " |            dict, with each key being the name of the metric. If `False`, they\n",
            " |            are returned as a list.\n",
            " |          **kwargs: Unused at this time.\n",
            " |      \n",
            " |      See the discussion of `Unpacking behavior for iterator-like inputs` for\n",
            " |      `Model.fit`.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Scalar test loss (if the model has a single output and no metrics)\n",
            " |          or list of scalars (if the model has multiple outputs\n",
            " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
            " |          the display labels for the scalar outputs.\n",
            " |      \n",
            " |      Raises:\n",
            " |          RuntimeError: If `model.evaluate` is wrapped in a `tf.function`.\n",
            " |  \n",
            " |  evaluate_generator(self, generator, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
            " |      Evaluates the model on a data generator.\n",
            " |      \n",
            " |      DEPRECATED:\n",
            " |        `Model.evaluate` now supports generators, so there is no longer any\n",
            " |        need to use this endpoint.\n",
            " |  \n",
            " |  export(self, filepath)\n",
            " |      Create a SavedModel artifact for inference (e.g. via TF-Serving).\n",
            " |      \n",
            " |      This method lets you export a model to a lightweight SavedModel artifact\n",
            " |      that contains the model's forward pass only (its `call()` method)\n",
            " |      and can be served via e.g. TF-Serving. The forward pass is registered\n",
            " |      under the name `serve()` (see example below).\n",
            " |      \n",
            " |      The original code of the model (including any custom layers you may\n",
            " |      have used) is *no longer* necessary to reload the artifact -- it is\n",
            " |      entirely standalone.\n",
            " |      \n",
            " |      Args:\n",
            " |          filepath: `str` or `pathlib.Path` object. Path where to save\n",
            " |              the artifact.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      # Create the artifact\n",
            " |      model.export(\"path/to/location\")\n",
            " |      \n",
            " |      # Later, in a different process / environment...\n",
            " |      reloaded_artifact = tf.saved_model.load(\"path/to/location\")\n",
            " |      predictions = reloaded_artifact.serve(input_data)\n",
            " |      ```\n",
            " |      \n",
            " |      If you would like to customize your serving endpoints, you can\n",
            " |      use the lower-level `keras.export.ExportArchive` class. The `export()`\n",
            " |      method relies on `ExportArchive` internally.\n",
            " |  \n",
            " |  fit(self, x=None, y=None, batch_size=None, epochs=1, verbose='auto', callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_batch_size=None, validation_freq=1, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
            " |      Trains the model for a fixed number of epochs (dataset iterations).\n",
            " |      \n",
            " |      Args:\n",
            " |          x: Input data. It could be:\n",
            " |            - A Numpy array (or array-like), or a list of arrays\n",
            " |              (in case the model has multiple inputs).\n",
            " |            - A TensorFlow tensor, or a list of tensors\n",
            " |              (in case the model has multiple inputs).\n",
            " |            - A dict mapping input names to the corresponding array/tensors,\n",
            " |              if the model has named inputs.\n",
            " |            - A `tf.data` dataset. Should return a tuple\n",
            " |              of either `(inputs, targets)` or\n",
            " |              `(inputs, targets, sample_weights)`.\n",
            " |            - A generator or `keras.utils.Sequence` returning `(inputs,\n",
            " |              targets)` or `(inputs, targets, sample_weights)`.\n",
            " |            - A `tf.keras.utils.experimental.DatasetCreator`, which wraps a\n",
            " |              callable that takes a single argument of type\n",
            " |              `tf.distribute.InputContext`, and returns a `tf.data.Dataset`.\n",
            " |              `DatasetCreator` should be used when users prefer to specify the\n",
            " |              per-replica batching and sharding logic for the `Dataset`.\n",
            " |              See `tf.keras.utils.experimental.DatasetCreator` doc for more\n",
            " |              information.\n",
            " |            A more detailed description of unpacking behavior for iterator\n",
            " |            types (Dataset, generator, Sequence) is given below. If these\n",
            " |            include `sample_weights` as a third component, note that sample\n",
            " |            weighting applies to the `weighted_metrics` argument but not the\n",
            " |            `metrics` argument in `compile()`. If using\n",
            " |            `tf.distribute.experimental.ParameterServerStrategy`, only\n",
            " |            `DatasetCreator` type is supported for `x`.\n",
            " |          y: Target data. Like the input data `x`,\n",
            " |            it could be either Numpy array(s) or TensorFlow tensor(s).\n",
            " |            It should be consistent with `x` (you cannot have Numpy inputs and\n",
            " |            tensor targets, or inversely). If `x` is a dataset, generator,\n",
            " |            or `keras.utils.Sequence` instance, `y` should\n",
            " |            not be specified (since targets will be obtained from `x`).\n",
            " |          batch_size: Integer or `None`.\n",
            " |              Number of samples per gradient update.\n",
            " |              If unspecified, `batch_size` will default to 32.\n",
            " |              Do not specify the `batch_size` if your data is in the\n",
            " |              form of datasets, generators, or `keras.utils.Sequence`\n",
            " |              instances (since they generate batches).\n",
            " |          epochs: Integer. Number of epochs to train the model.\n",
            " |              An epoch is an iteration over the entire `x` and `y`\n",
            " |              data provided\n",
            " |              (unless the `steps_per_epoch` flag is set to\n",
            " |              something other than None).\n",
            " |              Note that in conjunction with `initial_epoch`,\n",
            " |              `epochs` is to be understood as \"final epoch\".\n",
            " |              The model is not trained for a number of iterations\n",
            " |              given by `epochs`, but merely until the epoch\n",
            " |              of index `epochs` is reached.\n",
            " |          verbose: 'auto', 0, 1, or 2. Verbosity mode.\n",
            " |              0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
            " |              'auto' becomes 1 for most cases, but 2 when used with\n",
            " |              `ParameterServerStrategy`. Note that the progress bar is not\n",
            " |              particularly useful when logged to a file, so verbose=2 is\n",
            " |              recommended when not running interactively (eg, in a production\n",
            " |              environment). Defaults to 'auto'.\n",
            " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
            " |              List of callbacks to apply during training.\n",
            " |              See `tf.keras.callbacks`. Note\n",
            " |              `tf.keras.callbacks.ProgbarLogger` and\n",
            " |              `tf.keras.callbacks.History` callbacks are created automatically\n",
            " |              and need not be passed into `model.fit`.\n",
            " |              `tf.keras.callbacks.ProgbarLogger` is created or not based on\n",
            " |              `verbose` argument to `model.fit`.\n",
            " |              Callbacks with batch-level calls are currently unsupported with\n",
            " |              `tf.distribute.experimental.ParameterServerStrategy`, and users\n",
            " |              are advised to implement epoch-level calls instead with an\n",
            " |              appropriate `steps_per_epoch` value.\n",
            " |          validation_split: Float between 0 and 1.\n",
            " |              Fraction of the training data to be used as validation data.\n",
            " |              The model will set apart this fraction of the training data,\n",
            " |              will not train on it, and will evaluate\n",
            " |              the loss and any model metrics\n",
            " |              on this data at the end of each epoch.\n",
            " |              The validation data is selected from the last samples\n",
            " |              in the `x` and `y` data provided, before shuffling. This\n",
            " |              argument is not supported when `x` is a dataset, generator or\n",
            " |              `keras.utils.Sequence` instance.\n",
            " |              If both `validation_data` and `validation_split` are provided,\n",
            " |              `validation_data` will override `validation_split`.\n",
            " |              `validation_split` is not yet supported with\n",
            " |              `tf.distribute.experimental.ParameterServerStrategy`.\n",
            " |          validation_data: Data on which to evaluate\n",
            " |              the loss and any model metrics at the end of each epoch.\n",
            " |              The model will not be trained on this data. Thus, note the fact\n",
            " |              that the validation loss of data provided using\n",
            " |              `validation_split` or `validation_data` is not affected by\n",
            " |              regularization layers like noise and dropout.\n",
            " |              `validation_data` will override `validation_split`.\n",
            " |              `validation_data` could be:\n",
            " |                - A tuple `(x_val, y_val)` of Numpy arrays or tensors.\n",
            " |                - A tuple `(x_val, y_val, val_sample_weights)` of NumPy\n",
            " |                  arrays.\n",
            " |                - A `tf.data.Dataset`.\n",
            " |                - A Python generator or `keras.utils.Sequence` returning\n",
            " |                `(inputs, targets)` or `(inputs, targets, sample_weights)`.\n",
            " |              `validation_data` is not yet supported with\n",
            " |              `tf.distribute.experimental.ParameterServerStrategy`.\n",
            " |          shuffle: Boolean (whether to shuffle the training data\n",
            " |              before each epoch) or str (for 'batch'). This argument is\n",
            " |              ignored when `x` is a generator or an object of tf.data.Dataset.\n",
            " |              'batch' is a special option for dealing\n",
            " |              with the limitations of HDF5 data; it shuffles in batch-sized\n",
            " |              chunks. Has no effect when `steps_per_epoch` is not `None`.\n",
            " |          class_weight: Optional dictionary mapping class indices (integers)\n",
            " |              to a weight (float) value, used for weighting the loss function\n",
            " |              (during training only).\n",
            " |              This can be useful to tell the model to\n",
            " |              \"pay more attention\" to samples from\n",
            " |              an under-represented class. When `class_weight` is specified\n",
            " |              and targets have a rank of 2 or greater, either `y` must be\n",
            " |              one-hot encoded, or an explicit final dimension of `1` must\n",
            " |              be included for sparse class labels.\n",
            " |          sample_weight: Optional Numpy array of weights for\n",
            " |              the training samples, used for weighting the loss function\n",
            " |              (during training only). You can either pass a flat (1D)\n",
            " |              Numpy array with the same length as the input samples\n",
            " |              (1:1 mapping between weights and samples),\n",
            " |              or in the case of temporal data,\n",
            " |              you can pass a 2D array with shape\n",
            " |              `(samples, sequence_length)`,\n",
            " |              to apply a different weight to every timestep of every sample.\n",
            " |              This argument is not supported when `x` is a dataset, generator,\n",
            " |              or `keras.utils.Sequence` instance, instead provide the\n",
            " |              sample_weights as the third element of `x`.\n",
            " |              Note that sample weighting does not apply to metrics specified\n",
            " |              via the `metrics` argument in `compile()`. To apply sample\n",
            " |              weighting to your metrics, you can specify them via the\n",
            " |              `weighted_metrics` in `compile()` instead.\n",
            " |          initial_epoch: Integer.\n",
            " |              Epoch at which to start training\n",
            " |              (useful for resuming a previous training run).\n",
            " |          steps_per_epoch: Integer or `None`.\n",
            " |              Total number of steps (batches of samples)\n",
            " |              before declaring one epoch finished and starting the\n",
            " |              next epoch. When training with input tensors such as\n",
            " |              TensorFlow data tensors, the default `None` is equal to\n",
            " |              the number of samples in your dataset divided by\n",
            " |              the batch size, or 1 if that cannot be determined. If x is a\n",
            " |              `tf.data` dataset, and 'steps_per_epoch'\n",
            " |              is None, the epoch will run until the input dataset is\n",
            " |              exhausted.  When passing an infinitely repeating dataset, you\n",
            " |              must specify the `steps_per_epoch` argument. If\n",
            " |              `steps_per_epoch=-1` the training will run indefinitely with an\n",
            " |              infinitely repeating dataset.  This argument is not supported\n",
            " |              with array inputs.\n",
            " |              When using `tf.distribute.experimental.ParameterServerStrategy`:\n",
            " |                * `steps_per_epoch=None` is not supported.\n",
            " |          validation_steps: Only relevant if `validation_data` is provided and\n",
            " |              is a `tf.data` dataset. Total number of steps (batches of\n",
            " |              samples) to draw before stopping when performing validation\n",
            " |              at the end of every epoch. If 'validation_steps' is None,\n",
            " |              validation will run until the `validation_data` dataset is\n",
            " |              exhausted. In the case of an infinitely repeated dataset, it\n",
            " |              will run into an infinite loop. If 'validation_steps' is\n",
            " |              specified and only part of the dataset will be consumed, the\n",
            " |              evaluation will start from the beginning of the dataset at each\n",
            " |              epoch. This ensures that the same validation samples are used\n",
            " |              every time.\n",
            " |          validation_batch_size: Integer or `None`.\n",
            " |              Number of samples per validation batch.\n",
            " |              If unspecified, will default to `batch_size`.\n",
            " |              Do not specify the `validation_batch_size` if your data is in\n",
            " |              the form of datasets, generators, or `keras.utils.Sequence`\n",
            " |              instances (since they generate batches).\n",
            " |          validation_freq: Only relevant if validation data is provided.\n",
            " |            Integer or `collections.abc.Container` instance (e.g. list, tuple,\n",
            " |            etc.).  If an integer, specifies how many training epochs to run\n",
            " |            before a new validation run is performed, e.g. `validation_freq=2`\n",
            " |            runs validation every 2 epochs. If a Container, specifies the\n",
            " |            epochs on which to run validation, e.g.\n",
            " |            `validation_freq=[1, 2, 10]` runs validation at the end of the\n",
            " |            1st, 2nd, and 10th epochs.\n",
            " |          max_queue_size: Integer. Used for generator or\n",
            " |            `keras.utils.Sequence` input only. Maximum size for the generator\n",
            " |            queue.  If unspecified, `max_queue_size` will default to 10.\n",
            " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
            " |              only. Maximum number of processes to spin up\n",
            " |              when using process-based threading. If unspecified, `workers`\n",
            " |              will default to 1.\n",
            " |          use_multiprocessing: Boolean. Used for generator or\n",
            " |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
            " |              threading. If unspecified, `use_multiprocessing` will default to\n",
            " |              `False`. Note that because this implementation relies on\n",
            " |              multiprocessing, you should not pass non-pickleable arguments to\n",
            " |              the generator as they can't be passed easily to children\n",
            " |              processes.\n",
            " |      \n",
            " |      Unpacking behavior for iterator-like inputs:\n",
            " |          A common pattern is to pass a tf.data.Dataset, generator, or\n",
            " |        tf.keras.utils.Sequence to the `x` argument of fit, which will in fact\n",
            " |        yield not only features (x) but optionally targets (y) and sample\n",
            " |        weights.  Keras requires that the output of such iterator-likes be\n",
            " |        unambiguous. The iterator should return a tuple of length 1, 2, or 3,\n",
            " |        where the optional second and third elements will be used for y and\n",
            " |        sample_weight respectively. Any other type provided will be wrapped in\n",
            " |        a length one tuple, effectively treating everything as 'x'. When\n",
            " |        yielding dicts, they should still adhere to the top-level tuple\n",
            " |        structure.\n",
            " |        e.g. `({\"x0\": x0, \"x1\": x1}, y)`. Keras will not attempt to separate\n",
            " |        features, targets, and weights from the keys of a single dict.\n",
            " |          A notable unsupported data type is the namedtuple. The reason is\n",
            " |        that it behaves like both an ordered datatype (tuple) and a mapping\n",
            " |        datatype (dict). So given a namedtuple of the form:\n",
            " |            `namedtuple(\"example_tuple\", [\"y\", \"x\"])`\n",
            " |        it is ambiguous whether to reverse the order of the elements when\n",
            " |        interpreting the value. Even worse is a tuple of the form:\n",
            " |            `namedtuple(\"other_tuple\", [\"x\", \"y\", \"z\"])`\n",
            " |        where it is unclear if the tuple was intended to be unpacked into x,\n",
            " |        y, and sample_weight or passed through as a single element to `x`. As\n",
            " |        a result the data processing code will simply raise a ValueError if it\n",
            " |        encounters a namedtuple. (Along with instructions to remedy the\n",
            " |        issue.)\n",
            " |      \n",
            " |      Returns:\n",
            " |          A `History` object. Its `History.history` attribute is\n",
            " |          a record of training loss values and metrics values\n",
            " |          at successive epochs, as well as validation loss values\n",
            " |          and validation metrics values (if applicable).\n",
            " |      \n",
            " |      Raises:\n",
            " |          RuntimeError: 1. If the model was never compiled or,\n",
            " |          2. If `model.fit` is  wrapped in `tf.function`.\n",
            " |      \n",
            " |          ValueError: In case of mismatch between the provided input data\n",
            " |              and what the model expects or when the input data is empty.\n",
            " |  \n",
            " |  fit_generator(self, generator, steps_per_epoch=None, epochs=1, verbose=1, callbacks=None, validation_data=None, validation_steps=None, validation_freq=1, class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False, shuffle=True, initial_epoch=0)\n",
            " |      Fits the model on data yielded batch-by-batch by a Python generator.\n",
            " |      \n",
            " |      DEPRECATED:\n",
            " |        `Model.fit` now supports generators, so there is no longer any need to\n",
            " |        use this endpoint.\n",
            " |  \n",
            " |  get_compile_config(self)\n",
            " |      Returns a serialized config with information for compiling the model.\n",
            " |      \n",
            " |      This method returns a config dictionary containing all the information\n",
            " |      (optimizer, loss, metrics, etc.) with which the model was compiled.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A dict containing information for compiling the model.\n",
            " |  \n",
            " |  get_config(self)\n",
            " |      Returns the config of the `Model`.\n",
            " |      \n",
            " |      Config is a Python dictionary (serializable) containing the\n",
            " |      configuration of an object, which in this case is a `Model`. This allows\n",
            " |      the `Model` to be be reinstantiated later (without its trained weights)\n",
            " |      from this configuration.\n",
            " |      \n",
            " |      Note that `get_config()` does not guarantee to return a fresh copy of\n",
            " |      dict every time it is called. The callers should make a copy of the\n",
            " |      returned dict if they want to modify it.\n",
            " |      \n",
            " |      Developers of subclassed `Model` are advised to override this method,\n",
            " |      and continue to update the dict from `super(MyModel, self).get_config()`\n",
            " |      to provide the proper configuration of this `Model`. The default config\n",
            " |      will return config dict for init parameters if they are basic types.\n",
            " |      Raises `NotImplementedError` when in cases where a custom\n",
            " |      `get_config()` implementation is required for the subclassed model.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Python dictionary containing the configuration of this `Model`.\n",
            " |  \n",
            " |  get_layer(self, name=None, index=None)\n",
            " |      Retrieves a layer based on either its name (unique) or index.\n",
            " |      \n",
            " |      If `name` and `index` are both provided, `index` will take precedence.\n",
            " |      Indices are based on order of horizontal graph traversal (bottom-up).\n",
            " |      \n",
            " |      Args:\n",
            " |          name: String, name of layer.\n",
            " |          index: Integer, index of layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A layer instance.\n",
            " |  \n",
            " |  get_metrics_result(self)\n",
            " |      Returns the model's metrics values as a dict.\n",
            " |      \n",
            " |      If any of the metric result is a dict (containing multiple metrics),\n",
            " |      each of them gets added to the top level returned dict of this method.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `dict` containing values of the metrics listed in `self.metrics`.\n",
            " |        Example:\n",
            " |        `{'loss': 0.2, 'accuracy': 0.7}`.\n",
            " |  \n",
            " |  get_weight_paths(self)\n",
            " |      Retrieve all the variables and their paths for the model.\n",
            " |      \n",
            " |      The variable path (string) is a stable key to identify a `tf.Variable`\n",
            " |      instance owned by the model. It can be used to specify variable-specific\n",
            " |      configurations (e.g. DTensor, quantization) from a global view.\n",
            " |      \n",
            " |      This method returns a dict with weight object paths as keys\n",
            " |      and the corresponding `tf.Variable` instances as values.\n",
            " |      \n",
            " |      Note that if the model is a subclassed model and the weights haven't\n",
            " |      been initialized, an empty dict will be returned.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A dict where keys are variable paths and values are `tf.Variable`\n",
            " |           instances.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      class SubclassModel(tf.keras.Model):\n",
            " |      \n",
            " |        def __init__(self, name=None):\n",
            " |          super().__init__(name=name)\n",
            " |          self.d1 = tf.keras.layers.Dense(10)\n",
            " |          self.d2 = tf.keras.layers.Dense(20)\n",
            " |      \n",
            " |        def call(self, inputs):\n",
            " |          x = self.d1(inputs)\n",
            " |          return self.d2(x)\n",
            " |      \n",
            " |      model = SubclassModel()\n",
            " |      model(tf.zeros((10, 10)))\n",
            " |      weight_paths = model.get_weight_paths()\n",
            " |      # weight_paths:\n",
            " |      # {\n",
            " |      #    'd1.kernel': model.d1.kernel,\n",
            " |      #    'd1.bias': model.d1.bias,\n",
            " |      #    'd2.kernel': model.d2.kernel,\n",
            " |      #    'd2.bias': model.d2.bias,\n",
            " |      # }\n",
            " |      \n",
            " |      # Functional model\n",
            " |      inputs = tf.keras.Input((10,), batch_size=10)\n",
            " |      x = tf.keras.layers.Dense(20, name='d1')(inputs)\n",
            " |      output = tf.keras.layers.Dense(30, name='d2')(x)\n",
            " |      model = tf.keras.Model(inputs, output)\n",
            " |      d1 = model.layers[1]\n",
            " |      d2 = model.layers[2]\n",
            " |      weight_paths = model.get_weight_paths()\n",
            " |      # weight_paths:\n",
            " |      # {\n",
            " |      #    'd1.kernel': d1.kernel,\n",
            " |      #    'd1.bias': d1.bias,\n",
            " |      #    'd2.kernel': d2.kernel,\n",
            " |      #    'd2.bias': d2.bias,\n",
            " |      # }\n",
            " |      ```\n",
            " |  \n",
            " |  get_weights(self)\n",
            " |      Retrieves the weights of the model.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A flat list of Numpy arrays.\n",
            " |  \n",
            " |  load_weights(self, filepath, skip_mismatch=False, by_name=False, options=None)\n",
            " |      Loads all layer weights from a saved files.\n",
            " |      \n",
            " |      The saved file could be a SavedModel file, a `.keras` file (v3 saving\n",
            " |      format), or a file created via `model.save_weights()`.\n",
            " |      \n",
            " |      By default, weights are loaded based on the network's\n",
            " |      topology. This means the architecture should be the same as when the\n",
            " |      weights were saved. Note that layers that don't have weights are not\n",
            " |      taken into account in the topological ordering, so adding or removing\n",
            " |      layers is fine as long as they don't have weights.\n",
            " |      \n",
            " |      **Partial weight loading**\n",
            " |      \n",
            " |      If you have modified your model, for instance by adding a new layer\n",
            " |      (with weights) or by changing the shape of the weights of a layer,\n",
            " |      you can choose to ignore errors and continue loading\n",
            " |      by setting `skip_mismatch=True`. In this case any layer with\n",
            " |      mismatching weights will be skipped. A warning will be displayed\n",
            " |      for each skipped layer.\n",
            " |      \n",
            " |      **Weight loading by name**\n",
            " |      \n",
            " |      If your weights are saved as a `.h5` file created\n",
            " |      via `model.save_weights()`, you can use the argument `by_name=True`.\n",
            " |      \n",
            " |      In this case, weights are loaded into layers only if they share\n",
            " |      the same name. This is useful for fine-tuning or transfer-learning\n",
            " |      models where some of the layers have changed.\n",
            " |      \n",
            " |      Note that only topological loading (`by_name=False`) is supported when\n",
            " |      loading weights from the `.keras` v3 format or from the TensorFlow\n",
            " |      SavedModel format.\n",
            " |      \n",
            " |      Args:\n",
            " |          filepath: String, path to the weights file to load. For weight files\n",
            " |              in TensorFlow format, this is the file prefix (the same as was\n",
            " |              passed to `save_weights()`). This can also be a path to a\n",
            " |              SavedModel or a `.keras` file (v3 saving format) saved\n",
            " |              via `model.save()`.\n",
            " |          skip_mismatch: Boolean, whether to skip loading of layers where\n",
            " |              there is a mismatch in the number of weights, or a mismatch in\n",
            " |              the shape of the weights.\n",
            " |          by_name: Boolean, whether to load weights by name or by topological\n",
            " |              order. Only topological loading is supported for weight files in\n",
            " |              the `.keras` v3 format or in the TensorFlow SavedModel format.\n",
            " |          options: Optional `tf.train.CheckpointOptions` object that specifies\n",
            " |              options for loading weights (only valid for a SavedModel file).\n",
            " |  \n",
            " |  make_predict_function(self, force=False)\n",
            " |      Creates a function that executes one step of inference.\n",
            " |      \n",
            " |      This method can be overridden to support custom inference logic.\n",
            " |      This method is called by `Model.predict` and `Model.predict_on_batch`.\n",
            " |      \n",
            " |      Typically, this method directly controls `tf.function` and\n",
            " |      `tf.distribute.Strategy` settings, and delegates the actual evaluation\n",
            " |      logic to `Model.predict_step`.\n",
            " |      \n",
            " |      This function is cached the first time `Model.predict` or\n",
            " |      `Model.predict_on_batch` is called. The cache is cleared whenever\n",
            " |      `Model.compile` is called. You can skip the cache and generate again the\n",
            " |      function with `force=True`.\n",
            " |      \n",
            " |      Args:\n",
            " |        force: Whether to regenerate the predict function and skip the cached\n",
            " |          function if available.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Function. The function created by this method should accept a\n",
            " |        `tf.data.Iterator`, and return the outputs of the `Model`.\n",
            " |  \n",
            " |  make_test_function(self, force=False)\n",
            " |      Creates a function that executes one step of evaluation.\n",
            " |      \n",
            " |      This method can be overridden to support custom evaluation logic.\n",
            " |      This method is called by `Model.evaluate` and `Model.test_on_batch`.\n",
            " |      \n",
            " |      Typically, this method directly controls `tf.function` and\n",
            " |      `tf.distribute.Strategy` settings, and delegates the actual evaluation\n",
            " |      logic to `Model.test_step`.\n",
            " |      \n",
            " |      This function is cached the first time `Model.evaluate` or\n",
            " |      `Model.test_on_batch` is called. The cache is cleared whenever\n",
            " |      `Model.compile` is called. You can skip the cache and generate again the\n",
            " |      function with `force=True`.\n",
            " |      \n",
            " |      Args:\n",
            " |        force: Whether to regenerate the test function and skip the cached\n",
            " |          function if available.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Function. The function created by this method should accept a\n",
            " |        `tf.data.Iterator`, and return a `dict` containing values that will\n",
            " |        be passed to `tf.keras.Callbacks.on_test_batch_end`.\n",
            " |  \n",
            " |  make_train_function(self, force=False)\n",
            " |      Creates a function that executes one step of training.\n",
            " |      \n",
            " |      This method can be overridden to support custom training logic.\n",
            " |      This method is called by `Model.fit` and `Model.train_on_batch`.\n",
            " |      \n",
            " |      Typically, this method directly controls `tf.function` and\n",
            " |      `tf.distribute.Strategy` settings, and delegates the actual training\n",
            " |      logic to `Model.train_step`.\n",
            " |      \n",
            " |      This function is cached the first time `Model.fit` or\n",
            " |      `Model.train_on_batch` is called. The cache is cleared whenever\n",
            " |      `Model.compile` is called. You can skip the cache and generate again the\n",
            " |      function with `force=True`.\n",
            " |      \n",
            " |      Args:\n",
            " |        force: Whether to regenerate the train function and skip the cached\n",
            " |          function if available.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Function. The function created by this method should accept a\n",
            " |        `tf.data.Iterator`, and return a `dict` containing values that will\n",
            " |        be passed to `tf.keras.Callbacks.on_train_batch_end`, such as\n",
            " |        `{'loss': 0.2, 'accuracy': 0.7}`.\n",
            " |  \n",
            " |  predict(self, x, batch_size=None, verbose='auto', steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
            " |      Generates output predictions for the input samples.\n",
            " |      \n",
            " |      Computation is done in batches. This method is designed for batch\n",
            " |      processing of large numbers of inputs. It is not intended for use inside\n",
            " |      of loops that iterate over your data and process small numbers of inputs\n",
            " |      at a time.\n",
            " |      \n",
            " |      For small numbers of inputs that fit in one batch,\n",
            " |      directly use `__call__()` for faster execution, e.g.,\n",
            " |      `model(x)`, or `model(x, training=False)` if you have layers such as\n",
            " |      `tf.keras.layers.BatchNormalization` that behave differently during\n",
            " |      inference. You may pair the individual model call with a `tf.function`\n",
            " |      for additional performance inside your inner loop.\n",
            " |      If you need access to numpy array values instead of tensors after your\n",
            " |      model call, you can use `tensor.numpy()` to get the numpy array value of\n",
            " |      an eager tensor.\n",
            " |      \n",
            " |      Also, note the fact that test loss is not affected by\n",
            " |      regularization layers like noise and dropout.\n",
            " |      \n",
            " |      Note: See [this FAQ entry](\n",
            " |      https://keras.io/getting_started/faq/#whats-the-difference-between-model-methods-predict-and-call)\n",
            " |      for more details about the difference between `Model` methods\n",
            " |      `predict()` and `__call__()`.\n",
            " |      \n",
            " |      Args:\n",
            " |          x: Input samples. It could be:\n",
            " |            - A Numpy array (or array-like), or a list of arrays\n",
            " |              (in case the model has multiple inputs).\n",
            " |            - A TensorFlow tensor, or a list of tensors\n",
            " |              (in case the model has multiple inputs).\n",
            " |            - A `tf.data` dataset.\n",
            " |            - A generator or `keras.utils.Sequence` instance.\n",
            " |            A more detailed description of unpacking behavior for iterator\n",
            " |            types (Dataset, generator, Sequence) is given in the `Unpacking\n",
            " |            behavior for iterator-like inputs` section of `Model.fit`.\n",
            " |          batch_size: Integer or `None`.\n",
            " |              Number of samples per batch.\n",
            " |              If unspecified, `batch_size` will default to 32.\n",
            " |              Do not specify the `batch_size` if your data is in the\n",
            " |              form of dataset, generators, or `keras.utils.Sequence` instances\n",
            " |              (since they generate batches).\n",
            " |          verbose: `\"auto\"`, 0, 1, or 2. Verbosity mode.\n",
            " |              0 = silent, 1 = progress bar, 2 = single line.\n",
            " |              `\"auto\"` becomes 1 for most cases, and to 2 when used with\n",
            " |              `ParameterServerStrategy`. Note that the progress bar is not\n",
            " |              particularly useful when logged to a file, so `verbose=2` is\n",
            " |              recommended when not running interactively (e.g. in a production\n",
            " |              environment). Defaults to 'auto'.\n",
            " |          steps: Total number of steps (batches of samples)\n",
            " |              before declaring the prediction round finished.\n",
            " |              Ignored with the default value of `None`. If x is a `tf.data`\n",
            " |              dataset and `steps` is None, `predict()` will\n",
            " |              run until the input dataset is exhausted.\n",
            " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
            " |              List of callbacks to apply during prediction.\n",
            " |              See [callbacks](\n",
            " |              https://www.tensorflow.org/api_docs/python/tf/keras/callbacks).\n",
            " |          max_queue_size: Integer. Used for generator or\n",
            " |              `keras.utils.Sequence` input only. Maximum size for the\n",
            " |              generator queue. If unspecified, `max_queue_size` will default\n",
            " |              to 10.\n",
            " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
            " |              only. Maximum number of processes to spin up when using\n",
            " |              process-based threading. If unspecified, `workers` will default\n",
            " |              to 1.\n",
            " |          use_multiprocessing: Boolean. Used for generator or\n",
            " |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
            " |              threading. If unspecified, `use_multiprocessing` will default to\n",
            " |              `False`. Note that because this implementation relies on\n",
            " |              multiprocessing, you should not pass non-pickleable arguments to\n",
            " |              the generator as they can't be passed easily to children\n",
            " |              processes.\n",
            " |      \n",
            " |      See the discussion of `Unpacking behavior for iterator-like inputs` for\n",
            " |      `Model.fit`. Note that Model.predict uses the same interpretation rules\n",
            " |      as `Model.fit` and `Model.evaluate`, so inputs must be unambiguous for\n",
            " |      all three methods.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Numpy array(s) of predictions.\n",
            " |      \n",
            " |      Raises:\n",
            " |          RuntimeError: If `model.predict` is wrapped in a `tf.function`.\n",
            " |          ValueError: In case of mismatch between the provided\n",
            " |              input data and the model's expectations,\n",
            " |              or in case a stateful model receives a number of samples\n",
            " |              that is not a multiple of the batch size.\n",
            " |  \n",
            " |  predict_generator(self, generator, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
            " |      Generates predictions for the input samples from a data generator.\n",
            " |      \n",
            " |      DEPRECATED:\n",
            " |        `Model.predict` now supports generators, so there is no longer any\n",
            " |        need to use this endpoint.\n",
            " |  \n",
            " |  predict_on_batch(self, x)\n",
            " |      Returns predictions for a single batch of samples.\n",
            " |      \n",
            " |      Args:\n",
            " |          x: Input data. It could be:\n",
            " |            - A Numpy array (or array-like), or a list of arrays (in case the\n",
            " |                model has multiple inputs).\n",
            " |            - A TensorFlow tensor, or a list of tensors (in case the model has\n",
            " |                multiple inputs).\n",
            " |      \n",
            " |      Returns:\n",
            " |          Numpy array(s) of predictions.\n",
            " |      \n",
            " |      Raises:\n",
            " |          RuntimeError: If `model.predict_on_batch` is wrapped in a\n",
            " |            `tf.function`.\n",
            " |  \n",
            " |  predict_step(self, data)\n",
            " |      The logic for one inference step.\n",
            " |      \n",
            " |      This method can be overridden to support custom inference logic.\n",
            " |      This method is called by `Model.make_predict_function`.\n",
            " |      \n",
            " |      This method should contain the mathematical logic for one step of\n",
            " |      inference.  This typically includes the forward pass.\n",
            " |      \n",
            " |      Configuration details for *how* this logic is run (e.g. `tf.function`\n",
            " |      and `tf.distribute.Strategy` settings), should be left to\n",
            " |      `Model.make_predict_function`, which can also be overridden.\n",
            " |      \n",
            " |      Args:\n",
            " |        data: A nested structure of `Tensor`s.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The result of one inference step, typically the output of calling the\n",
            " |        `Model` on data.\n",
            " |  \n",
            " |  reset_metrics(self)\n",
            " |      Resets the state of all the metrics in the model.\n",
            " |      \n",
            " |      Examples:\n",
            " |      \n",
            " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
            " |      >>> outputs = tf.keras.layers.Dense(2)(inputs)\n",
            " |      >>> model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
            " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
            " |      \n",
            " |      >>> x = np.random.random((2, 3))\n",
            " |      >>> y = np.random.randint(0, 2, (2, 2))\n",
            " |      >>> _ = model.fit(x, y, verbose=0)\n",
            " |      >>> assert all(float(m.result()) for m in model.metrics)\n",
            " |      \n",
            " |      >>> model.reset_metrics()\n",
            " |      >>> assert all(float(m.result()) == 0 for m in model.metrics)\n",
            " |  \n",
            " |  reset_states(self)\n",
            " |  \n",
            " |  save(self, filepath, overwrite=True, save_format=None, **kwargs)\n",
            " |      Saves a model as a TensorFlow SavedModel or HDF5 file.\n",
            " |      \n",
            " |      See the [Serialization and Saving guide](\n",
            " |          https://keras.io/guides/serialization_and_saving/) for details.\n",
            " |      \n",
            " |      Args:\n",
            " |          model: Keras model instance to be saved.\n",
            " |          filepath: `str` or `pathlib.Path` object. Path where to save the\n",
            " |              model.\n",
            " |          overwrite: Whether we should overwrite any existing model at the\n",
            " |              target location, or instead ask the user via an interactive\n",
            " |              prompt.\n",
            " |          save_format: Either `\"keras\"`, `\"tf\"`, `\"h5\"`,\n",
            " |              indicating whether to save the model\n",
            " |              in the native Keras format (`.keras`),\n",
            " |              in the TensorFlow SavedModel format\n",
            " |              (referred to as \"SavedModel\" below),\n",
            " |              or in the legacy HDF5 format (`.h5`).\n",
            " |              Defaults to `\"tf\"` in TF 2.X, and `\"h5\"` in TF 1.X.\n",
            " |      \n",
            " |      SavedModel format arguments:\n",
            " |          include_optimizer: Only applied to SavedModel and legacy HDF5\n",
            " |              formats. If False, do not save the optimizer state.\n",
            " |              Defaults to `True`.\n",
            " |          signatures: Only applies to SavedModel format. Signatures to save\n",
            " |              with the SavedModel. See the `signatures` argument in\n",
            " |              `tf.saved_model.save` for details.\n",
            " |          options: Only applies to SavedModel format.\n",
            " |              `tf.saved_model.SaveOptions` object that specifies SavedModel\n",
            " |              saving options.\n",
            " |          save_traces: Only applies to SavedModel format. When enabled, the\n",
            " |              SavedModel will store the function traces for each layer. This\n",
            " |              can be disabled, so that only the configs of each layer are\n",
            " |              stored. Defaults to `True`.\n",
            " |              Disabling this will decrease serialization time\n",
            " |              and reduce file size, but it requires that all custom\n",
            " |              layers/models implement a `get_config()` method.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      model = tf.keras.Sequential([\n",
            " |          tf.keras.layers.Dense(5, input_shape=(3,)),\n",
            " |          tf.keras.layers.Softmax()])\n",
            " |      model.save(\"model.keras\")\n",
            " |      loaded_model = tf.keras.models.load_model(\"model.keras\")\n",
            " |      x = tf.random.uniform((10, 3))\n",
            " |      assert np.allclose(model.predict(x), loaded_model.predict(x))\n",
            " |      ```\n",
            " |      \n",
            " |      Note that `model.save()` is an alias for `tf.keras.models.save_model()`.\n",
            " |  \n",
            " |  save_spec(self, dynamic_batch=True)\n",
            " |      Returns the `tf.TensorSpec` of call args as a tuple `(args, kwargs)`.\n",
            " |      \n",
            " |      This value is automatically defined after calling the model for the\n",
            " |      first time. Afterwards, you can use it when exporting the model for\n",
            " |      serving:\n",
            " |      \n",
            " |      ```python\n",
            " |      model = tf.keras.Model(...)\n",
            " |      \n",
            " |      @tf.function\n",
            " |      def serve(*args, **kwargs):\n",
            " |        outputs = model(*args, **kwargs)\n",
            " |        # Apply postprocessing steps, or add additional outputs.\n",
            " |        ...\n",
            " |        return outputs\n",
            " |      \n",
            " |      # arg_specs is `[tf.TensorSpec(...), ...]`. kwarg_specs, in this\n",
            " |      # example, is an empty dict since functional models do not use keyword\n",
            " |      # arguments.\n",
            " |      arg_specs, kwarg_specs = model.save_spec()\n",
            " |      \n",
            " |      model.save(path, signatures={\n",
            " |        'serving_default': serve.get_concrete_function(*arg_specs,\n",
            " |                                                       **kwarg_specs)\n",
            " |      })\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |        dynamic_batch: Whether to set the batch sizes of all the returned\n",
            " |          `tf.TensorSpec` to `None`. (Note that when defining functional or\n",
            " |          Sequential models with `tf.keras.Input([...], batch_size=X)`, the\n",
            " |          batch size will always be preserved). Defaults to `True`.\n",
            " |      Returns:\n",
            " |        If the model inputs are defined, returns a tuple `(args, kwargs)`. All\n",
            " |        elements in `args` and `kwargs` are `tf.TensorSpec`.\n",
            " |        If the model inputs are not defined, returns `None`.\n",
            " |        The model inputs are automatically set when calling the model,\n",
            " |        `model.fit`, `model.evaluate` or `model.predict`.\n",
            " |  \n",
            " |  save_weights(self, filepath, overwrite=True, save_format=None, options=None)\n",
            " |      Saves all layer weights.\n",
            " |      \n",
            " |      Either saves in HDF5 or in TensorFlow format based on the `save_format`\n",
            " |      argument.\n",
            " |      \n",
            " |      When saving in HDF5 format, the weight file has:\n",
            " |        - `layer_names` (attribute), a list of strings\n",
            " |            (ordered names of model layers).\n",
            " |        - For every layer, a `group` named `layer.name`\n",
            " |            - For every such layer group, a group attribute `weight_names`,\n",
            " |                a list of strings\n",
            " |                (ordered names of weights tensor of the layer).\n",
            " |            - For every weight in the layer, a dataset\n",
            " |                storing the weight value, named after the weight tensor.\n",
            " |      \n",
            " |      When saving in TensorFlow format, all objects referenced by the network\n",
            " |      are saved in the same format as `tf.train.Checkpoint`, including any\n",
            " |      `Layer` instances or `Optimizer` instances assigned to object\n",
            " |      attributes. For networks constructed from inputs and outputs using\n",
            " |      `tf.keras.Model(inputs, outputs)`, `Layer` instances used by the network\n",
            " |      are tracked/saved automatically. For user-defined classes which inherit\n",
            " |      from `tf.keras.Model`, `Layer` instances must be assigned to object\n",
            " |      attributes, typically in the constructor. See the documentation of\n",
            " |      `tf.train.Checkpoint` and `tf.keras.Model` for details.\n",
            " |      \n",
            " |      While the formats are the same, do not mix `save_weights` and\n",
            " |      `tf.train.Checkpoint`. Checkpoints saved by `Model.save_weights` should\n",
            " |      be loaded using `Model.load_weights`. Checkpoints saved using\n",
            " |      `tf.train.Checkpoint.save` should be restored using the corresponding\n",
            " |      `tf.train.Checkpoint.restore`. Prefer `tf.train.Checkpoint` over\n",
            " |      `save_weights` for training checkpoints.\n",
            " |      \n",
            " |      The TensorFlow format matches objects and variables by starting at a\n",
            " |      root object, `self` for `save_weights`, and greedily matching attribute\n",
            " |      names. For `Model.save` this is the `Model`, and for `Checkpoint.save`\n",
            " |      this is the `Checkpoint` even if the `Checkpoint` has a model attached.\n",
            " |      This means saving a `tf.keras.Model` using `save_weights` and loading\n",
            " |      into a `tf.train.Checkpoint` with a `Model` attached (or vice versa)\n",
            " |      will not match the `Model`'s variables. See the\n",
            " |      [guide to training checkpoints](\n",
            " |      https://www.tensorflow.org/guide/checkpoint) for details on\n",
            " |      the TensorFlow format.\n",
            " |      \n",
            " |      Args:\n",
            " |          filepath: String or PathLike, path to the file to save the weights\n",
            " |              to. When saving in TensorFlow format, this is the prefix used\n",
            " |              for checkpoint files (multiple files are generated). Note that\n",
            " |              the '.h5' suffix causes weights to be saved in HDF5 format.\n",
            " |          overwrite: Whether to silently overwrite any existing file at the\n",
            " |              target location, or provide the user with a manual prompt.\n",
            " |          save_format: Either 'tf' or 'h5'. A `filepath` ending in '.h5' or\n",
            " |              '.keras' will default to HDF5 if `save_format` is `None`.\n",
            " |              Otherwise, `None` becomes 'tf'. Defaults to `None`.\n",
            " |          options: Optional `tf.train.CheckpointOptions` object that specifies\n",
            " |              options for saving weights.\n",
            " |      \n",
            " |      Raises:\n",
            " |          ImportError: If `h5py` is not available when attempting to save in\n",
            " |              HDF5 format.\n",
            " |  \n",
            " |  summary(self, line_length=None, positions=None, print_fn=None, expand_nested=False, show_trainable=False, layer_range=None)\n",
            " |      Prints a string summary of the network.\n",
            " |      \n",
            " |      Args:\n",
            " |          line_length: Total length of printed lines\n",
            " |              (e.g. set this to adapt the display to different\n",
            " |              terminal window sizes).\n",
            " |          positions: Relative or absolute positions of log elements\n",
            " |              in each line. If not provided, becomes\n",
            " |              `[0.3, 0.6, 0.70, 1.]`. Defaults to `None`.\n",
            " |          print_fn: Print function to use. By default, prints to `stdout`.\n",
            " |              If `stdout` doesn't work in your environment, change to `print`.\n",
            " |              It will be called on each line of the summary.\n",
            " |              You can set it to a custom function\n",
            " |              in order to capture the string summary.\n",
            " |          expand_nested: Whether to expand the nested models.\n",
            " |              Defaults to `False`.\n",
            " |          show_trainable: Whether to show if a layer is trainable.\n",
            " |              Defaults to `False`.\n",
            " |          layer_range: a list or tuple of 2 strings,\n",
            " |              which is the starting layer name and ending layer name\n",
            " |              (both inclusive) indicating the range of layers to be printed\n",
            " |              in summary. It also accepts regex patterns instead of exact\n",
            " |              name. In such case, start predicate will be the first element\n",
            " |              it matches to `layer_range[0]` and the end predicate will be\n",
            " |              the last element it matches to `layer_range[1]`.\n",
            " |              By default `None` which considers all layers of model.\n",
            " |      \n",
            " |      Raises:\n",
            " |          ValueError: if `summary()` is called before the model is built.\n",
            " |  \n",
            " |  test_on_batch(self, x, y=None, sample_weight=None, reset_metrics=True, return_dict=False)\n",
            " |      Test the model on a single batch of samples.\n",
            " |      \n",
            " |      Args:\n",
            " |          x: Input data. It could be:\n",
            " |            - A Numpy array (or array-like), or a list of arrays (in case the\n",
            " |                model has multiple inputs).\n",
            " |            - A TensorFlow tensor, or a list of tensors (in case the model has\n",
            " |                multiple inputs).\n",
            " |            - A dict mapping input names to the corresponding array/tensors,\n",
            " |                if the model has named inputs.\n",
            " |          y: Target data. Like the input data `x`, it could be either Numpy\n",
            " |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
            " |            (you cannot have Numpy inputs and tensor targets, or inversely).\n",
            " |          sample_weight: Optional array of the same length as x, containing\n",
            " |            weights to apply to the model's loss for each sample. In the case\n",
            " |            of temporal data, you can pass a 2D array with shape (samples,\n",
            " |            sequence_length), to apply a different weight to every timestep of\n",
            " |            every sample.\n",
            " |          reset_metrics: If `True`, the metrics returned will be only for this\n",
            " |            batch. If `False`, the metrics will be statefully accumulated\n",
            " |            across batches.\n",
            " |          return_dict: If `True`, loss and metric results are returned as a\n",
            " |            dict, with each key being the name of the metric. If `False`, they\n",
            " |            are returned as a list.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Scalar test loss (if the model has a single output and no metrics)\n",
            " |          or list of scalars (if the model has multiple outputs\n",
            " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
            " |          the display labels for the scalar outputs.\n",
            " |      \n",
            " |      Raises:\n",
            " |          RuntimeError: If `model.test_on_batch` is wrapped in a\n",
            " |            `tf.function`.\n",
            " |  \n",
            " |  test_step(self, data)\n",
            " |      The logic for one evaluation step.\n",
            " |      \n",
            " |      This method can be overridden to support custom evaluation logic.\n",
            " |      This method is called by `Model.make_test_function`.\n",
            " |      \n",
            " |      This function should contain the mathematical logic for one step of\n",
            " |      evaluation.\n",
            " |      This typically includes the forward pass, loss calculation, and metrics\n",
            " |      updates.\n",
            " |      \n",
            " |      Configuration details for *how* this logic is run (e.g. `tf.function`\n",
            " |      and `tf.distribute.Strategy` settings), should be left to\n",
            " |      `Model.make_test_function`, which can also be overridden.\n",
            " |      \n",
            " |      Args:\n",
            " |        data: A nested structure of `Tensor`s.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `dict` containing values that will be passed to\n",
            " |        `tf.keras.callbacks.CallbackList.on_train_batch_end`. Typically, the\n",
            " |        values of the `Model`'s metrics are returned.\n",
            " |  \n",
            " |  to_json(self, **kwargs)\n",
            " |      Returns a JSON string containing the network configuration.\n",
            " |      \n",
            " |      To load a network from a JSON save file, use\n",
            " |      `keras.models.model_from_json(json_string, custom_objects={})`.\n",
            " |      \n",
            " |      Args:\n",
            " |          **kwargs: Additional keyword arguments to be passed to\n",
            " |              *`json.dumps()`.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A JSON string.\n",
            " |  \n",
            " |  to_yaml(self, **kwargs)\n",
            " |      Returns a yaml string containing the network configuration.\n",
            " |      \n",
            " |      Note: Since TF 2.6, this method is no longer supported and will raise a\n",
            " |      RuntimeError.\n",
            " |      \n",
            " |      To load a network from a yaml save file, use\n",
            " |      `keras.models.model_from_yaml(yaml_string, custom_objects={})`.\n",
            " |      \n",
            " |      `custom_objects` should be a dictionary mapping\n",
            " |      the names of custom losses / layers / etc to the corresponding\n",
            " |      functions / classes.\n",
            " |      \n",
            " |      Args:\n",
            " |          **kwargs: Additional keyword arguments\n",
            " |              to be passed to `yaml.dump()`.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A YAML string.\n",
            " |      \n",
            " |      Raises:\n",
            " |          RuntimeError: announces that the method poses a security risk\n",
            " |  \n",
            " |  train_on_batch(self, x, y=None, sample_weight=None, class_weight=None, reset_metrics=True, return_dict=False)\n",
            " |      Runs a single gradient update on a single batch of data.\n",
            " |      \n",
            " |      Args:\n",
            " |          x: Input data. It could be:\n",
            " |            - A Numpy array (or array-like), or a list of arrays\n",
            " |                (in case the model has multiple inputs).\n",
            " |            - A TensorFlow tensor, or a list of tensors\n",
            " |                (in case the model has multiple inputs).\n",
            " |            - A dict mapping input names to the corresponding array/tensors,\n",
            " |                if the model has named inputs.\n",
            " |          y: Target data. Like the input data `x`, it could be either Numpy\n",
            " |            array(s) or TensorFlow tensor(s).\n",
            " |          sample_weight: Optional array of the same length as x, containing\n",
            " |            weights to apply to the model's loss for each sample. In the case\n",
            " |            of temporal data, you can pass a 2D array with shape (samples,\n",
            " |            sequence_length), to apply a different weight to every timestep of\n",
            " |            every sample.\n",
            " |          class_weight: Optional dictionary mapping class indices (integers)\n",
            " |            to a weight (float) to apply to the model's loss for the samples\n",
            " |            from this class during training. This can be useful to tell the\n",
            " |            model to \"pay more attention\" to samples from an under-represented\n",
            " |            class. When `class_weight` is specified and targets have a rank of\n",
            " |            2 or greater, either `y` must be one-hot encoded, or an explicit\n",
            " |            final dimension of `1` must be included for sparse class labels.\n",
            " |          reset_metrics: If `True`, the metrics returned will be only for this\n",
            " |            batch. If `False`, the metrics will be statefully accumulated\n",
            " |            across batches.\n",
            " |          return_dict: If `True`, loss and metric results are returned as a\n",
            " |            dict, with each key being the name of the metric. If `False`, they\n",
            " |            are returned as a list.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Scalar training loss\n",
            " |          (if the model has a single output and no metrics)\n",
            " |          or list of scalars (if the model has multiple outputs\n",
            " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
            " |          the display labels for the scalar outputs.\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If `model.train_on_batch` is wrapped in a `tf.function`.\n",
            " |  \n",
            " |  train_step(self, data)\n",
            " |      The logic for one training step.\n",
            " |      \n",
            " |      This method can be overridden to support custom training logic.\n",
            " |      For concrete examples of how to override this method see\n",
            " |      [Customizing what happens in fit](\n",
            " |      https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit).\n",
            " |      This method is called by `Model.make_train_function`.\n",
            " |      \n",
            " |      This method should contain the mathematical logic for one step of\n",
            " |      training.  This typically includes the forward pass, loss calculation,\n",
            " |      backpropagation, and metric updates.\n",
            " |      \n",
            " |      Configuration details for *how* this logic is run (e.g. `tf.function`\n",
            " |      and `tf.distribute.Strategy` settings), should be left to\n",
            " |      `Model.make_train_function`, which can also be overridden.\n",
            " |      \n",
            " |      Args:\n",
            " |        data: A nested structure of `Tensor`s.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `dict` containing values that will be passed to\n",
            " |        `tf.keras.callbacks.CallbackList.on_train_batch_end`. Typically, the\n",
            " |        values of the `Model`'s metrics are returned. Example:\n",
            " |        `{'loss': 0.2, 'accuracy': 0.7}`.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Class methods defined here:\n",
            " |  \n",
            " |  from_config(config, custom_objects=None) from builtins.type\n",
            " |      Creates a layer from its config.\n",
            " |      \n",
            " |      This method is the reverse of `get_config`,\n",
            " |      capable of instantiating the same layer from the config\n",
            " |      dictionary. It does not handle layer connectivity\n",
            " |      (handled by Network), nor weights (handled by `set_weights`).\n",
            " |      \n",
            " |      Args:\n",
            " |          config: A Python dictionary, typically the\n",
            " |              output of get_config.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A layer instance.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Static methods defined here:\n",
            " |  \n",
            " |  __new__(cls, *args, **kwargs)\n",
            " |      Create and return a new object.  See help(type) for accurate signature.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Readonly properties defined here:\n",
            " |  \n",
            " |  distribute_strategy\n",
            " |      The `tf.distribute.Strategy` this model was created under.\n",
            " |  \n",
            " |  metrics\n",
            " |      Return metrics added using `compile()` or `add_metric()`.\n",
            " |      \n",
            " |      Note: Metrics passed to `compile()` are available only after a\n",
            " |      `keras.Model` has been trained/evaluated on actual data.\n",
            " |      \n",
            " |      Examples:\n",
            " |      \n",
            " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
            " |      >>> outputs = tf.keras.layers.Dense(2)(inputs)\n",
            " |      >>> model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
            " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
            " |      >>> [m.name for m in model.metrics]\n",
            " |      []\n",
            " |      \n",
            " |      >>> x = np.random.random((2, 3))\n",
            " |      >>> y = np.random.randint(0, 2, (2, 2))\n",
            " |      >>> model.fit(x, y)\n",
            " |      >>> [m.name for m in model.metrics]\n",
            " |      ['loss', 'mae']\n",
            " |      \n",
            " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
            " |      >>> d = tf.keras.layers.Dense(2, name='out')\n",
            " |      >>> output_1 = d(inputs)\n",
            " |      >>> output_2 = d(inputs)\n",
            " |      >>> model = tf.keras.models.Model(\n",
            " |      ...    inputs=inputs, outputs=[output_1, output_2])\n",
            " |      >>> model.add_metric(\n",
            " |      ...    tf.reduce_sum(output_2), name='mean', aggregation='mean')\n",
            " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\", \"acc\"])\n",
            " |      >>> model.fit(x, (y, y))\n",
            " |      >>> [m.name for m in model.metrics]\n",
            " |      ['loss', 'out_loss', 'out_1_loss', 'out_mae', 'out_acc', 'out_1_mae',\n",
            " |      'out_1_acc', 'mean']\n",
            " |  \n",
            " |  metrics_names\n",
            " |      Returns the model's display labels for all outputs.\n",
            " |      \n",
            " |      Note: `metrics_names` are available only after a `keras.Model` has been\n",
            " |      trained/evaluated on actual data.\n",
            " |      \n",
            " |      Examples:\n",
            " |      \n",
            " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
            " |      >>> outputs = tf.keras.layers.Dense(2)(inputs)\n",
            " |      >>> model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
            " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
            " |      >>> model.metrics_names\n",
            " |      []\n",
            " |      \n",
            " |      >>> x = np.random.random((2, 3))\n",
            " |      >>> y = np.random.randint(0, 2, (2, 2))\n",
            " |      >>> model.fit(x, y)\n",
            " |      >>> model.metrics_names\n",
            " |      ['loss', 'mae']\n",
            " |      \n",
            " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
            " |      >>> d = tf.keras.layers.Dense(2, name='out')\n",
            " |      >>> output_1 = d(inputs)\n",
            " |      >>> output_2 = d(inputs)\n",
            " |      >>> model = tf.keras.models.Model(\n",
            " |      ...    inputs=inputs, outputs=[output_1, output_2])\n",
            " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\", \"acc\"])\n",
            " |      >>> model.fit(x, (y, y))\n",
            " |      >>> model.metrics_names\n",
            " |      ['loss', 'out_loss', 'out_1_loss', 'out_mae', 'out_acc', 'out_1_mae',\n",
            " |      'out_1_acc']\n",
            " |  \n",
            " |  non_trainable_weights\n",
            " |      List of all non-trainable weights tracked by this layer.\n",
            " |      \n",
            " |      Non-trainable weights are *not* updated during training. They are\n",
            " |      expected to be updated manually in `call()`.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A list of non-trainable variables.\n",
            " |  \n",
            " |  state_updates\n",
            " |      Deprecated, do NOT use!\n",
            " |      \n",
            " |      Returns the `updates` from all layers that are stateful.\n",
            " |      \n",
            " |      This is useful for separating training updates and\n",
            " |      state updates, e.g. when we need to update a layer's internal state\n",
            " |      during prediction.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A list of update ops.\n",
            " |  \n",
            " |  trainable_weights\n",
            " |      List of all trainable weights tracked by this layer.\n",
            " |      \n",
            " |      Trainable weights are updated via gradient descent during training.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A list of trainable variables.\n",
            " |  \n",
            " |  weights\n",
            " |      Returns the list of all layer variables/weights.\n",
            " |      \n",
            " |      Note: This will not track the weights of nested `tf.Modules` that are\n",
            " |      not themselves Keras layers.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A list of variables.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors defined here:\n",
            " |  \n",
            " |  autotune_steps_per_execution\n",
            " |      Settable property to enable tuning for steps_per_execution\n",
            " |  \n",
            " |  distribute_reduction_method\n",
            " |      The method employed to reduce per-replica values during training.\n",
            " |      \n",
            " |      Unless specified, the value \"auto\" will be assumed, indicating that\n",
            " |      the reduction strategy should be chosen based on the current\n",
            " |      running environment.\n",
            " |      See `reduce_per_replica` function for more details.\n",
            " |  \n",
            " |  jit_compile\n",
            " |      Specify whether to compile the model with XLA.\n",
            " |      \n",
            " |      [XLA](https://www.tensorflow.org/xla) is an optimizing compiler\n",
            " |      for machine learning. `jit_compile` is not enabled by default.\n",
            " |      Note that `jit_compile=True` may not necessarily work for all models.\n",
            " |      \n",
            " |      For more information on supported operations please refer to the\n",
            " |      [XLA documentation](https://www.tensorflow.org/xla). Also refer to\n",
            " |      [known XLA issues](https://www.tensorflow.org/xla/known_issues)\n",
            " |      for more details.\n",
            " |  \n",
            " |  layers\n",
            " |  \n",
            " |  run_eagerly\n",
            " |      Settable attribute indicating whether the model should run eagerly.\n",
            " |      \n",
            " |      Running eagerly means that your model will be run step by step,\n",
            " |      like Python code. Your model might run slower, but it should become\n",
            " |      easier for you to debug it by stepping into individual layer calls.\n",
            " |      \n",
            " |      By default, we will attempt to compile your model to a static graph to\n",
            " |      deliver the best execution performance.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Boolean, whether the model should run eagerly.\n",
            " |  \n",
            " |  steps_per_execution\n",
            " |      Settable `steps_per_execution variable. Requires a compiled model.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes defined here:\n",
            " |  \n",
            " |  __annotations__ = {}\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from keras.src.engine.base_layer.Layer:\n",
            " |  \n",
            " |  __delattr__(self, name)\n",
            " |      Implement delattr(self, name).\n",
            " |  \n",
            " |  __getstate__(self)\n",
            " |  \n",
            " |  __setstate__(self, state)\n",
            " |  \n",
            " |  add_loss(self, losses, **kwargs)\n",
            " |      Add loss tensor(s), potentially dependent on layer inputs.\n",
            " |      \n",
            " |      Some losses (for instance, activity regularization losses) may be\n",
            " |      dependent on the inputs passed when calling a layer. Hence, when reusing\n",
            " |      the same layer on different inputs `a` and `b`, some entries in\n",
            " |      `layer.losses` may be dependent on `a` and some on `b`. This method\n",
            " |      automatically keeps track of dependencies.\n",
            " |      \n",
            " |      This method can be used inside a subclassed layer or model's `call`\n",
            " |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      class MyLayer(tf.keras.layers.Layer):\n",
            " |        def call(self, inputs):\n",
            " |          self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
            " |          return inputs\n",
            " |      ```\n",
            " |      \n",
            " |      The same code works in distributed training: the input to `add_loss()`\n",
            " |      is treated like a regularization loss and averaged across replicas\n",
            " |      by the training loop (both built-in `Model.fit()` and compliant custom\n",
            " |      training loops).\n",
            " |      \n",
            " |      The `add_loss` method can also be called directly on a Functional Model\n",
            " |      during construction. In this case, any loss Tensors passed to this Model\n",
            " |      must be symbolic and be able to be traced back to the model's `Input`s.\n",
            " |      These losses become part of the model's topology and are tracked in\n",
            " |      `get_config`.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      inputs = tf.keras.Input(shape=(10,))\n",
            " |      x = tf.keras.layers.Dense(10)(inputs)\n",
            " |      outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      model = tf.keras.Model(inputs, outputs)\n",
            " |      # Activity regularization.\n",
            " |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
            " |      ```\n",
            " |      \n",
            " |      If this is not the case for your loss (if, for example, your loss\n",
            " |      references a `Variable` of one of the model's layers), you can wrap your\n",
            " |      loss in a zero-argument lambda. These losses are not tracked as part of\n",
            " |      the model's topology since they can't be serialized.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      inputs = tf.keras.Input(shape=(10,))\n",
            " |      d = tf.keras.layers.Dense(10)\n",
            " |      x = d(inputs)\n",
            " |      outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      model = tf.keras.Model(inputs, outputs)\n",
            " |      # Weight regularization.\n",
            " |      model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors,\n",
            " |          losses may also be zero-argument callables which create a loss\n",
            " |          tensor.\n",
            " |        **kwargs: Used for backwards compatibility only.\n",
            " |  \n",
            " |  add_metric(self, value, name=None, **kwargs)\n",
            " |      Adds metric tensor to the layer.\n",
            " |      \n",
            " |      This method can be used inside the `call()` method of a subclassed layer\n",
            " |      or model.\n",
            " |      \n",
            " |      ```python\n",
            " |      class MyMetricLayer(tf.keras.layers.Layer):\n",
            " |        def __init__(self):\n",
            " |          super(MyMetricLayer, self).__init__(name='my_metric_layer')\n",
            " |          self.mean = tf.keras.metrics.Mean(name='metric_1')\n",
            " |      \n",
            " |        def call(self, inputs):\n",
            " |          self.add_metric(self.mean(inputs))\n",
            " |          self.add_metric(tf.reduce_sum(inputs), name='metric_2')\n",
            " |          return inputs\n",
            " |      ```\n",
            " |      \n",
            " |      This method can also be called directly on a Functional Model during\n",
            " |      construction. In this case, any tensor passed to this Model must\n",
            " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
            " |      metrics become part of the model's topology and are tracked when you\n",
            " |      save the model via `save()`.\n",
            " |      \n",
            " |      ```python\n",
            " |      inputs = tf.keras.Input(shape=(10,))\n",
            " |      x = tf.keras.layers.Dense(10)(inputs)\n",
            " |      outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      model = tf.keras.Model(inputs, outputs)\n",
            " |      model.add_metric(math_ops.reduce_sum(x), name='metric_1')\n",
            " |      ```\n",
            " |      \n",
            " |      Note: Calling `add_metric()` with the result of a metric object on a\n",
            " |      Functional Model, as shown in the example below, is not supported. This\n",
            " |      is because we cannot trace the metric result tensor back to the model's\n",
            " |      inputs.\n",
            " |      \n",
            " |      ```python\n",
            " |      inputs = tf.keras.Input(shape=(10,))\n",
            " |      x = tf.keras.layers.Dense(10)(inputs)\n",
            " |      outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      model = tf.keras.Model(inputs, outputs)\n",
            " |      model.add_metric(tf.keras.metrics.Mean()(x), name='metric_1')\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |        value: Metric tensor.\n",
            " |        name: String metric name.\n",
            " |        **kwargs: Additional keyword arguments for backward compatibility.\n",
            " |          Accepted values:\n",
            " |          `aggregation` - When the `value` tensor provided is not the result\n",
            " |          of calling a `keras.Metric` instance, it will be aggregated by\n",
            " |          default using a `keras.Metric.Mean`.\n",
            " |  \n",
            " |  add_update(self, updates)\n",
            " |      Add update op(s), potentially dependent on layer inputs.\n",
            " |      \n",
            " |      Weight updates (for instance, the updates of the moving mean and\n",
            " |      variance in a BatchNormalization layer) may be dependent on the inputs\n",
            " |      passed when calling a layer. Hence, when reusing the same layer on\n",
            " |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
            " |      dependent on `a` and some on `b`. This method automatically keeps track\n",
            " |      of dependencies.\n",
            " |      \n",
            " |      This call is ignored when eager execution is enabled (in that case,\n",
            " |      variable updates are run on the fly and thus do not need to be tracked\n",
            " |      for later execution).\n",
            " |      \n",
            " |      Args:\n",
            " |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
            " |          that returns an update op. A zero-arg callable should be passed in\n",
            " |          order to disable running the updates by setting `trainable=False`\n",
            " |          on this Layer, when executing in Eager mode.\n",
            " |  \n",
            " |  add_variable(self, *args, **kwargs)\n",
            " |      Deprecated, do NOT use! Alias for `add_weight`.\n",
            " |  \n",
            " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregationV2.NONE: 0>, **kwargs)\n",
            " |      Adds a new variable to the layer.\n",
            " |      \n",
            " |      Args:\n",
            " |        name: Variable name.\n",
            " |        shape: Variable shape. Defaults to scalar if unspecified.\n",
            " |        dtype: The type of the variable. Defaults to `self.dtype`.\n",
            " |        initializer: Initializer instance (callable).\n",
            " |        regularizer: Regularizer instance (callable).\n",
            " |        trainable: Boolean, whether the variable should be part of the layer's\n",
            " |          \"trainable_variables\" (e.g. variables, biases)\n",
            " |          or \"non_trainable_variables\" (e.g. BatchNorm mean and variance).\n",
            " |          Note that `trainable` cannot be `True` if `synchronization`\n",
            " |          is set to `ON_READ`.\n",
            " |        constraint: Constraint instance (callable).\n",
            " |        use_resource: Whether to use a `ResourceVariable` or not.\n",
            " |          See [this guide](\n",
            " |          https://www.tensorflow.org/guide/migrate/tf1_vs_tf2#resourcevariables_instead_of_referencevariables)\n",
            " |           for more information.\n",
            " |        synchronization: Indicates when a distributed a variable will be\n",
            " |          aggregated. Accepted values are constants defined in the class\n",
            " |          `tf.VariableSynchronization`. By default the synchronization is set\n",
            " |          to `AUTO` and the current `DistributionStrategy` chooses when to\n",
            " |          synchronize. If `synchronization` is set to `ON_READ`, `trainable`\n",
            " |          must not be set to `True`.\n",
            " |        aggregation: Indicates how a distributed variable will be aggregated.\n",
            " |          Accepted values are constants defined in the class\n",
            " |          `tf.VariableAggregation`.\n",
            " |        **kwargs: Additional keyword arguments. Accepted values are `getter`,\n",
            " |          `collections`, `experimental_autocast` and `caching_device`.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The variable created.\n",
            " |      \n",
            " |      Raises:\n",
            " |        ValueError: When giving unsupported dtype and no initializer or when\n",
            " |          trainable has been set to True with synchronization set as\n",
            " |          `ON_READ`.\n",
            " |  \n",
            " |  build_from_config(self, config)\n",
            " |      Builds the layer's states with the supplied config dict.\n",
            " |      \n",
            " |      By default, this method calls the `build(config[\"input_shape\"])` method,\n",
            " |      which creates weights based on the layer's input shape in the supplied\n",
            " |      config. If your config contains other information needed to load the\n",
            " |      layer's state, you should override this method.\n",
            " |      \n",
            " |      Args:\n",
            " |          config: Dict containing the input shape associated with this layer.\n",
            " |  \n",
            " |  compute_mask(self, inputs, mask=None)\n",
            " |      Computes an output mask tensor.\n",
            " |      \n",
            " |      Args:\n",
            " |          inputs: Tensor or list of tensors.\n",
            " |          mask: Tensor or list of tensors.\n",
            " |      \n",
            " |      Returns:\n",
            " |          None or a tensor (or list of tensors,\n",
            " |              one per output tensor of the layer).\n",
            " |  \n",
            " |  compute_output_shape(self, input_shape)\n",
            " |      Computes the output shape of the layer.\n",
            " |      \n",
            " |      This method will cause the layer's state to be built, if that has not\n",
            " |      happened before. This requires that the layer will later be used with\n",
            " |      inputs that match the input shape provided here.\n",
            " |      \n",
            " |      Args:\n",
            " |          input_shape: Shape tuple (tuple of integers) or `tf.TensorShape`,\n",
            " |              or structure of shape tuples / `tf.TensorShape` instances\n",
            " |              (one per output tensor of the layer).\n",
            " |              Shape tuples can include None for free dimensions,\n",
            " |              instead of an integer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A `tf.TensorShape` instance\n",
            " |          or structure of `tf.TensorShape` instances.\n",
            " |  \n",
            " |  compute_output_signature(self, input_signature)\n",
            " |      Compute the output tensor signature of the layer based on the inputs.\n",
            " |      \n",
            " |      Unlike a TensorShape object, a TensorSpec object contains both shape\n",
            " |      and dtype information for a tensor. This method allows layers to provide\n",
            " |      output dtype information if it is different from the input dtype.\n",
            " |      For any layer that doesn't implement this function,\n",
            " |      the framework will fall back to use `compute_output_shape`, and will\n",
            " |      assume that the output dtype matches the input dtype.\n",
            " |      \n",
            " |      Args:\n",
            " |        input_signature: Single TensorSpec or nested structure of TensorSpec\n",
            " |          objects, describing a candidate input for the layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Single TensorSpec or nested structure of TensorSpec objects,\n",
            " |          describing how the layer would transform the provided input.\n",
            " |      \n",
            " |      Raises:\n",
            " |        TypeError: If input_signature contains a non-TensorSpec object.\n",
            " |  \n",
            " |  count_params(self)\n",
            " |      Count the total number of scalars composing the weights.\n",
            " |      \n",
            " |      Returns:\n",
            " |          An integer count.\n",
            " |      \n",
            " |      Raises:\n",
            " |          ValueError: if the layer isn't yet built\n",
            " |            (in which case its weights aren't yet defined).\n",
            " |  \n",
            " |  finalize_state(self)\n",
            " |      Finalizes the layers state after updating layer weights.\n",
            " |      \n",
            " |      This function can be subclassed in a layer and will be called after\n",
            " |      updating a layer weights. It can be overridden to finalize any\n",
            " |      additional layer state after a weight update.\n",
            " |      \n",
            " |      This function will be called after weights of a layer have been restored\n",
            " |      from a loaded model.\n",
            " |  \n",
            " |  get_build_config(self)\n",
            " |      Returns a dictionary with the layer's input shape.\n",
            " |      \n",
            " |      This method returns a config dict that can be used by\n",
            " |      `build_from_config(config)` to create all states (e.g. Variables and\n",
            " |      Lookup tables) needed by the layer.\n",
            " |      \n",
            " |      By default, the config only contains the input shape that the layer\n",
            " |      was built with. If you're writing a custom layer that creates state in\n",
            " |      an unusual way, you should override this method to make sure this state\n",
            " |      is already created when Keras attempts to load its value upon model\n",
            " |      loading.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A dict containing the input shape associated with the layer.\n",
            " |  \n",
            " |  get_input_at(self, node_index)\n",
            " |      Retrieves the input tensor(s) of a layer at a given node.\n",
            " |      \n",
            " |      Args:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first input node of the layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If called in Eager mode.\n",
            " |  \n",
            " |  get_input_mask_at(self, node_index)\n",
            " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
            " |      \n",
            " |      Args:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first time the layer was called.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A mask tensor\n",
            " |          (or list of tensors if the layer has multiple inputs).\n",
            " |  \n",
            " |  get_input_shape_at(self, node_index)\n",
            " |      Retrieves the input shape(s) of a layer at a given node.\n",
            " |      \n",
            " |      Args:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first time the layer was called.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A shape tuple\n",
            " |          (or list of shape tuples if the layer has multiple inputs).\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If called in Eager mode.\n",
            " |  \n",
            " |  get_output_at(self, node_index)\n",
            " |      Retrieves the output tensor(s) of a layer at a given node.\n",
            " |      \n",
            " |      Args:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first output node of the layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If called in Eager mode.\n",
            " |  \n",
            " |  get_output_mask_at(self, node_index)\n",
            " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
            " |      \n",
            " |      Args:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first time the layer was called.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A mask tensor\n",
            " |          (or list of tensors if the layer has multiple outputs).\n",
            " |  \n",
            " |  get_output_shape_at(self, node_index)\n",
            " |      Retrieves the output shape(s) of a layer at a given node.\n",
            " |      \n",
            " |      Args:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first time the layer was called.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A shape tuple\n",
            " |          (or list of shape tuples if the layer has multiple outputs).\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If called in Eager mode.\n",
            " |  \n",
            " |  load_own_variables(self, store)\n",
            " |      Loads the state of the layer.\n",
            " |      \n",
            " |      You can override this method to take full control of how the state of\n",
            " |      the layer is loaded upon calling `keras.models.load_model()`.\n",
            " |      \n",
            " |      Args:\n",
            " |          store: Dict from which the state of the model will be loaded.\n",
            " |  \n",
            " |  save_own_variables(self, store)\n",
            " |      Saves the state of the layer.\n",
            " |      \n",
            " |      You can override this method to take full control of how the state of\n",
            " |      the layer is saved upon calling `model.save()`.\n",
            " |      \n",
            " |      Args:\n",
            " |          store: Dict where the state of the model will be saved.\n",
            " |  \n",
            " |  set_weights(self, weights)\n",
            " |      Sets the weights of the layer, from NumPy arrays.\n",
            " |      \n",
            " |      The weights of a layer represent the state of the layer. This function\n",
            " |      sets the weight values from numpy arrays. The weight values should be\n",
            " |      passed in the order they are created by the layer. Note that the layer's\n",
            " |      weights must be instantiated before calling this function, by calling\n",
            " |      the layer.\n",
            " |      \n",
            " |      For example, a `Dense` layer returns a list of two values: the kernel\n",
            " |      matrix and the bias vector. These can be used to set the weights of\n",
            " |      another `Dense` layer:\n",
            " |      \n",
            " |      >>> layer_a = tf.keras.layers.Dense(1,\n",
            " |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
            " |      >>> a_out = layer_a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
            " |      >>> layer_a.get_weights()\n",
            " |      [array([[1.],\n",
            " |             [1.],\n",
            " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
            " |      >>> layer_b = tf.keras.layers.Dense(1,\n",
            " |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
            " |      >>> b_out = layer_b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
            " |      >>> layer_b.get_weights()\n",
            " |      [array([[2.],\n",
            " |             [2.],\n",
            " |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
            " |      >>> layer_b.set_weights(layer_a.get_weights())\n",
            " |      >>> layer_b.get_weights()\n",
            " |      [array([[1.],\n",
            " |             [1.],\n",
            " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
            " |      \n",
            " |      Args:\n",
            " |        weights: a list of NumPy arrays. The number\n",
            " |          of arrays and their shape must match\n",
            " |          number of the dimensions of the weights\n",
            " |          of the layer (i.e. it should match the\n",
            " |          output of `get_weights`).\n",
            " |      \n",
            " |      Raises:\n",
            " |        ValueError: If the provided weights list does not match the\n",
            " |          layer's specifications.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Readonly properties inherited from keras.src.engine.base_layer.Layer:\n",
            " |  \n",
            " |  compute_dtype\n",
            " |      The dtype of the layer's computations.\n",
            " |      \n",
            " |      This is equivalent to `Layer.dtype_policy.compute_dtype`. Unless\n",
            " |      mixed precision is used, this is the same as `Layer.dtype`, the dtype of\n",
            " |      the weights.\n",
            " |      \n",
            " |      Layers automatically cast their inputs to the compute dtype, which\n",
            " |      causes computations and the output to be in the compute dtype as well.\n",
            " |      This is done by the base Layer class in `Layer.__call__`, so you do not\n",
            " |      have to insert these casts if implementing your own layer.\n",
            " |      \n",
            " |      Layers often perform certain internal computations in higher precision\n",
            " |      when `compute_dtype` is float16 or bfloat16 for numeric stability. The\n",
            " |      output will still typically be float16 or bfloat16 in such cases.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The layer's compute dtype.\n",
            " |  \n",
            " |  dtype\n",
            " |      The dtype of the layer weights.\n",
            " |      \n",
            " |      This is equivalent to `Layer.dtype_policy.variable_dtype`. Unless\n",
            " |      mixed precision is used, this is the same as `Layer.compute_dtype`, the\n",
            " |      dtype of the layer's computations.\n",
            " |  \n",
            " |  dtype_policy\n",
            " |      The dtype policy associated with this layer.\n",
            " |      \n",
            " |      This is an instance of a `tf.keras.mixed_precision.Policy`.\n",
            " |  \n",
            " |  dynamic\n",
            " |      Whether the layer is dynamic (eager-only); set in the constructor.\n",
            " |  \n",
            " |  inbound_nodes\n",
            " |      Return Functional API nodes upstream of this layer.\n",
            " |  \n",
            " |  input\n",
            " |      Retrieves the input tensor(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has exactly one input,\n",
            " |      i.e. if it is connected to one incoming layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Input tensor or list of input tensors.\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If called in Eager mode.\n",
            " |        AttributeError: If no inbound nodes are found.\n",
            " |  \n",
            " |  input_mask\n",
            " |      Retrieves the input mask tensor(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has exactly one inbound node,\n",
            " |      i.e. if it is connected to one incoming layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Input mask tensor (potentially None) or list of input\n",
            " |          mask tensors.\n",
            " |      \n",
            " |      Raises:\n",
            " |          AttributeError: if the layer is connected to\n",
            " |          more than one incoming layers.\n",
            " |  \n",
            " |  input_shape\n",
            " |      Retrieves the input shape(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has exactly one input,\n",
            " |      i.e. if it is connected to one incoming layer, or if all inputs\n",
            " |      have the same shape.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Input shape, as an integer shape tuple\n",
            " |          (or list of shape tuples, one tuple per input tensor).\n",
            " |      \n",
            " |      Raises:\n",
            " |          AttributeError: if the layer has no defined input_shape.\n",
            " |          RuntimeError: if called in Eager mode.\n",
            " |  \n",
            " |  losses\n",
            " |      List of losses added using the `add_loss()` API.\n",
            " |      \n",
            " |      Variable regularization tensors are created when this property is\n",
            " |      accessed, so it is eager safe: accessing `losses` under a\n",
            " |      `tf.GradientTape` will propagate gradients back to the corresponding\n",
            " |      variables.\n",
            " |      \n",
            " |      Examples:\n",
            " |      \n",
            " |      >>> class MyLayer(tf.keras.layers.Layer):\n",
            " |      ...   def call(self, inputs):\n",
            " |      ...     self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
            " |      ...     return inputs\n",
            " |      >>> l = MyLayer()\n",
            " |      >>> l(np.ones((10, 1)))\n",
            " |      >>> l.losses\n",
            " |      [1.0]\n",
            " |      \n",
            " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
            " |      >>> x = tf.keras.layers.Dense(10)(inputs)\n",
            " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      >>> model = tf.keras.Model(inputs, outputs)\n",
            " |      >>> # Activity regularization.\n",
            " |      >>> len(model.losses)\n",
            " |      0\n",
            " |      >>> model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
            " |      >>> len(model.losses)\n",
            " |      1\n",
            " |      \n",
            " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
            " |      >>> d = tf.keras.layers.Dense(10, kernel_initializer='ones')\n",
            " |      >>> x = d(inputs)\n",
            " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      >>> model = tf.keras.Model(inputs, outputs)\n",
            " |      >>> # Weight regularization.\n",
            " |      >>> model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
            " |      >>> model.losses\n",
            " |      [<tf.Tensor: shape=(), dtype=float32, numpy=1.0>]\n",
            " |      \n",
            " |      Returns:\n",
            " |        A list of tensors.\n",
            " |  \n",
            " |  name\n",
            " |      Name of the layer (string), set in the constructor.\n",
            " |  \n",
            " |  non_trainable_variables\n",
            " |      Sequence of non-trainable variables owned by this module and its submodules.\n",
            " |      \n",
            " |      Note: this method uses reflection to find variables on the current instance\n",
            " |      and submodules. For performance reasons you may wish to cache the result\n",
            " |      of calling this method if you don't expect the return value to change.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A sequence of variables for the current module (sorted by attribute\n",
            " |        name) followed by variables from all submodules recursively (breadth\n",
            " |        first).\n",
            " |  \n",
            " |  outbound_nodes\n",
            " |      Return Functional API nodes downstream of this layer.\n",
            " |  \n",
            " |  output\n",
            " |      Retrieves the output tensor(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has exactly one output,\n",
            " |      i.e. if it is connected to one incoming layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Output tensor or list of output tensors.\n",
            " |      \n",
            " |      Raises:\n",
            " |        AttributeError: if the layer is connected to more than one incoming\n",
            " |          layers.\n",
            " |        RuntimeError: if called in Eager mode.\n",
            " |  \n",
            " |  output_mask\n",
            " |      Retrieves the output mask tensor(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has exactly one inbound node,\n",
            " |      i.e. if it is connected to one incoming layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Output mask tensor (potentially None) or list of output\n",
            " |          mask tensors.\n",
            " |      \n",
            " |      Raises:\n",
            " |          AttributeError: if the layer is connected to\n",
            " |          more than one incoming layers.\n",
            " |  \n",
            " |  output_shape\n",
            " |      Retrieves the output shape(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has one output,\n",
            " |      or if all outputs have the same shape.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Output shape, as an integer shape tuple\n",
            " |          (or list of shape tuples, one tuple per output tensor).\n",
            " |      \n",
            " |      Raises:\n",
            " |          AttributeError: if the layer has no defined output shape.\n",
            " |          RuntimeError: if called in Eager mode.\n",
            " |  \n",
            " |  trainable_variables\n",
            " |      Sequence of trainable variables owned by this module and its submodules.\n",
            " |      \n",
            " |      Note: this method uses reflection to find variables on the current instance\n",
            " |      and submodules. For performance reasons you may wish to cache the result\n",
            " |      of calling this method if you don't expect the return value to change.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A sequence of variables for the current module (sorted by attribute\n",
            " |        name) followed by variables from all submodules recursively (breadth\n",
            " |        first).\n",
            " |  \n",
            " |  updates\n",
            " |  \n",
            " |  variable_dtype\n",
            " |      Alias of `Layer.dtype`, the dtype of the weights.\n",
            " |  \n",
            " |  variables\n",
            " |      Returns the list of all layer variables/weights.\n",
            " |      \n",
            " |      Alias of `self.weights`.\n",
            " |      \n",
            " |      Note: This will not track the weights of nested `tf.Modules` that are\n",
            " |      not themselves Keras layers.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A list of variables.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from keras.src.engine.base_layer.Layer:\n",
            " |  \n",
            " |  activity_regularizer\n",
            " |      Optional regularizer function for the output of this layer.\n",
            " |  \n",
            " |  input_spec\n",
            " |      `InputSpec` instance(s) describing the input format for this layer.\n",
            " |      \n",
            " |      When you create a layer subclass, you can set `self.input_spec` to\n",
            " |      enable the layer to run input compatibility checks when it is called.\n",
            " |      Consider a `Conv2D` layer: it can only be called on a single input\n",
            " |      tensor of rank 4. As such, you can set, in `__init__()`:\n",
            " |      \n",
            " |      ```python\n",
            " |      self.input_spec = tf.keras.layers.InputSpec(ndim=4)\n",
            " |      ```\n",
            " |      \n",
            " |      Now, if you try to call the layer on an input that isn't rank 4\n",
            " |      (for instance, an input of shape `(2,)`, it will raise a\n",
            " |      nicely-formatted error:\n",
            " |      \n",
            " |      ```\n",
            " |      ValueError: Input 0 of layer conv2d is incompatible with the layer:\n",
            " |      expected ndim=4, found ndim=1. Full shape received: [2]\n",
            " |      ```\n",
            " |      \n",
            " |      Input checks that can be specified via `input_spec` include:\n",
            " |      - Structure (e.g. a single input, a list of 2 inputs, etc)\n",
            " |      - Shape\n",
            " |      - Rank (ndim)\n",
            " |      - Dtype\n",
            " |      \n",
            " |      For more information, see `tf.keras.layers.InputSpec`.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `tf.keras.layers.InputSpec` instance, or nested structure thereof.\n",
            " |  \n",
            " |  stateful\n",
            " |  \n",
            " |  supports_masking\n",
            " |      Whether this layer supports computing a mask using `compute_mask`.\n",
            " |  \n",
            " |  trainable\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
            " |  \n",
            " |  with_name_scope(method) from builtins.type\n",
            " |      Decorator to automatically enter the module name scope.\n",
            " |      \n",
            " |      >>> class MyModule(tf.Module):\n",
            " |      ...   @tf.Module.with_name_scope\n",
            " |      ...   def __call__(self, x):\n",
            " |      ...     if not hasattr(self, 'w'):\n",
            " |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
            " |      ...     return tf.matmul(x, self.w)\n",
            " |      \n",
            " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
            " |      names included the module name:\n",
            " |      \n",
            " |      >>> mod = MyModule()\n",
            " |      >>> mod(tf.ones([1, 2]))\n",
            " |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
            " |      >>> mod.w\n",
            " |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
            " |      numpy=..., dtype=float32)>\n",
            " |      \n",
            " |      Args:\n",
            " |        method: The method to wrap.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The original method wrapped such that it enters the module's name scope.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Readonly properties inherited from tensorflow.python.module.module.Module:\n",
            " |  \n",
            " |  name_scope\n",
            " |      Returns a `tf.name_scope` instance for this class.\n",
            " |  \n",
            " |  submodules\n",
            " |      Sequence of all sub-modules.\n",
            " |      \n",
            " |      Submodules are modules which are properties of this module, or found as\n",
            " |      properties of modules which are properties of this module (and so on).\n",
            " |      \n",
            " |      >>> a = tf.Module()\n",
            " |      >>> b = tf.Module()\n",
            " |      >>> c = tf.Module()\n",
            " |      >>> a.b = b\n",
            " |      >>> b.c = c\n",
            " |      >>> list(a.submodules) == [b, c]\n",
            " |      True\n",
            " |      >>> list(b.submodules) == [c]\n",
            " |      True\n",
            " |      >>> list(c.submodules) == []\n",
            " |      True\n",
            " |      \n",
            " |      Returns:\n",
            " |        A sequence of all submodules.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from tensorflow.python.trackable.base.Trackable:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            "\n"
          ]
        }
      ]
    }
  ]
}